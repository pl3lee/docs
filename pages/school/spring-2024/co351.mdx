import { Definition, DefinitionName, DefinitionContent, Corollary, CorollaryName, CorollaryContent, Example, ExampleName, ExampleContent, Problem, ProblemName, ProblemContent, Proposition, PropositionName, PropositionContent, Theorem, TheoremName, TheoremContent, Lemma, LemmaName, LemmaContent, Proof, ProofName, ProofContent } from "/components/math";
import { Steps, Callout } from 'nextra/components'

# CO 351: Network Flow Theory
Notes are taken from Martin Pei's [lecture videos](https://www.youtube.com/@uwco351networkflowtheory8/playlists) since I find them to be a lot more clear and organized compared to the in-class lectures.
## Graphs
Let's start with basic definitions of graphs.
<Definition withName={true}>
    <DefinitionName>Graph Definitions</DefinitionName>
    <DefinitionContent>
        - A **graph** $G$ is a pair $(V, E)$ where $V$ is a finite set and $E$ is a set of unordered pairs of distinct elements of $V$.
        - The **degree** of a vertex $v$ is the number of edges incident to $v$. We use the notation $d_G(v)$ or $d(v)$ to denote the degree of $v$ in graph $G$.
        - A **walk** $Q$ is a non-empty sequence of edges. For example, $v_1v_2,v_2v_3,\ldots,v_{k-1}v_k$. We can abbreviate this by only writing the vertices: $v_1,v_2,\ldots, v_k$.

            Note that an edge may appear several times in a walk.
        - A **path** $P$ is a walk such that $v_1,\ldots,v_k$ are distinct vertices, meaning that we visit a new node at each step.
        - A **cycle** $C = v_1,\ldots,v_k$ is a walk such that $k \geq 3$ and $v_1 = v_k$ with $v_1,\ldots,v_{k-1}$ being distinct.
        - An **$st$-walk** is a walk that starts at $s$ and ends at $t$.
        - An **$st$-path** is a path that starts at $s$ and ends at $t$, with $s \neq t$.
        - Consider an edge $ij$, then $i$ and $j$ are **adjacent vertices**, $i$ and $j$ are the **endpoints** of the edge, and the edge $ij$ is said to be **incident** to vertices $i$ and $j$.
    </DefinitionContent>
</Definition>
<Definition withName={true}>
    <DefinitionName>Connectivity and Cuts</DefinitionName>
    <DefinitionContent>
        - A graph $G = (V, E)$ is **connected** if for each pair $i, j \in V$, there exists an $ij$-path.
        - For a subset of vertices $S \subseteq V$, the **cut** with shore $S$ is the set of edges with exactly one endpoint in $S$. We use the notation
            $$
            \delta(S) = \{ij \in E : i \in S, j \notin S\}
            $$
            For example, we have
            $$
            \delta(S) = \{e_{12}, e_{25}, e_{35}, e_{45}, e_{14}\}
            $$
            for the following
            ![Cut Example](/images/school/spring-2024/co351/1-1.png)
        - For vertices $s$ and $t$ with $s \neq t$ of $G$, and **$st$-cut** of $G$ is a cut $\delta(S)$ where $S \subset V$, with $s \in S$ and $t \notin S$. 
        
            Using the example from above, if we have $s = v_1$ and $t = v_3$, then the above is an $st$-cut.
    </DefinitionContent>
</Definition>
Now, we have our first theorem.
<Theorem>
    <TheoremContent>
        Let $G = (V, E)$ be a graph, and let $s, t$ be vertices of $G$. Then there exists an $st$-path if and only if every $st$-cut is non-empty.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        $(\Rightarrow)$ Suppose that there exists an $st$-path $P = v_1,\ldots,v_k$ where $s = v_1$, and $t = v_k$. We prove that every $st$-cut is non-empty. Let $\delta(\hat S)$ be any $st$-cut, where $s \in \hat S$ and $t \notin \hat S$. Let $\ell$ be the largest index such that $v_\ell \in \hat S$, and note that $\ell \neq k$ since $v_k = t$ is not in $\hat S$. So, we have that $v_{\ell + 1}$ is not in $\hat S$. Thus, the edge $v_\ell v_{\ell + 1}$ is in $\delta(\hat S)$, hence $\delta(\hat S) \neq \emptyset$.

        ![](/images/school/spring-2024/co351/1-2.png)

        $(\Leftarrow)$ Assume that every $st$-cut is non-empty. Suppose for contradiction that no $st$-path exists. We let $S$ be the set of vertices which can be reached from $s$. By construction, we have $s \in S$, and $t \not \in S$ since no $st$-path exists (and thus $t$ is not reachable from $s$). Moreover, for all $u \in S$ and $v \not \in S$, there exists an $su$-path (since $u \in S$), but there is no $sv$-path (since $v \not \in S$). So, we also have that $v$ is not reachable from $u$. Since this is true for all $u \in S$ and $v \not \in S$, this means that there are no edges originating from $S$ to $V \setminus S$. Thus, $\delta(S) = \emptyset$, which is a contradiction. Therefore, there exists an $st$-path.

        ![](/images/school/spring-2024/co351/1-3.png)
    </ProofContent>
</Proof>
<Definition>
    <DefinitionName>Trees</DefinitionName>
    <DefinitionContent>
        - A **tree** is a connected digraph that contains no cycles. Note that a tree with $n$ vertices has $n-1$ edges.
        - A **spanning tree** of a graph $G$ is a subgraph $T$ of $H$ such that $V(T) = V(G)$ and $T$ is a tree.
        - Note that a graph $G$ has a spanning tree if and only if $G$ is connected.
    </DefinitionContent>
</Definition>
<Lemma>
    <LemmaContent>
        For a tree $T$ and any two vertices $i$ and $j$ of $T$, there is a unique $ij$-path in $T$.
    </LemmaContent>
</Lemma>
<Theorem number="1.7">
    <TheoremContent>
        Let $T = (U, F)$ be a tree. Then
        1. For any edge $e \not \in F$, graph $T + e = (U, F \cup \{e\})$ has exactly one cycle $C$.
        2. For any edge $e' \in C$, where $C$ is the cycle from 1, the graph $T + e - e' = (U, F \cup \{e\} \setminus \{e'\})$ is a tree.
    </TheoremContent>
</Theorem>
Note that the cycle from the first part of the theorem is called the **fundamental cycle** of the edge $e$.
<Definition>
    <DefinitionName>Fundamental Cycle</DefinitionName>
    <DefinitionContent>
        The fundamental cycle of a given tree $T$ is the unique cycle of $T + e$, where $e$ is an edge and $e \not \in E(T)$.
    </DefinitionContent>
</Definition>
To prove the theorem above, we will need the following lemmas.
<Lemma number="1.8">
    <LemmaContent>
        For any graph $G$, if there exists a $uv$-path and a $vw$-path, then there exists a $uw$-path.
    </LemmaContent>
</Lemma>
<Proof withName={true}>
    <ProofName>Sketch</ProofName>
    <ProofContent>
        Note that we cannot just take the union of the paths, as there might be overlaps. However, a union of the paths does give us a walk from $u$ to $w$. We can then use the fact that a walk can be converted to a path by removing cycles.
    </ProofContent>
</Proof>

<Lemma number="1.9">
    <LemmaContent>
        Let $G$ be a connected graph with a cycle $C$, let $e$ be an edge of $C$. Then $G - e$ is connected.
    </LemmaContent>
</Lemma>
<Proof>
    <ProofContent>
        Let $v_1,v_2$ be any pair of vertices of $G - e$. We want to show that there exists a $v_1v_2$-path $P'$ of $G - e$, and thus $G - e$ is connected.

        Since $G$ is connected, there exists a $v_1v_2$-path $P$ of $G$. If $P$ does not contain $e$, then $P$ is also a $v_1v_2$-path of $G - e$, and we are done.

        Otherwise, $P$ contains $e$. Let $e = uw$. Since $G$ is connected, there exists a $v_1u$-path $P_1$ and a $wv_2$-path $P_2$. Moreover, $C - e = C - uw$ is a $uw$-path. Thus, by the Lemma 1.8, since there exists a $v_1u$-path and a $uw$-path, there exists a $v_1w$-path. Then, since there exists a $v_1w$-path and a $wv_2$-path, there exists a $v_1v_2$-path. Thus, $G - e$ is connected.
    </ProofContent>
</Proof>

<Lemma number="1.10">
    <LemmaContent>
        In a tree $T$, any 2 vertices are connected by a **unique** path.
    </LemmaContent>
</Lemma>
<Proof>
    <ProofContent>
        Assume for contradiction that there exists two distinct $uv$-paths $P_1$ and $P_2$ in $T$. Then the parts of $P_1$ and $P_2$ can be joined together to form a cycle, which is a contradiction since trees do not have cycles. 
    </ProofContent>
</Proof>
Now, we can finally prove Theorem 1.7.
<Proof withName={true}>
    <ProofName>Theorem 1.7</ProofName>
    <ProofContent>
        Since $T$ is acyclic, each cycle of $T + e$ contains $e = xy$. Moreover, $C$ is a cycle of $T + e$ if and only if $C - e$ is a $xy$-path of $T$.

        By Lemma 1.10, $T$ contains a unique $xy$-path, therefore $T + e$ contains a unique cycle $C$. This proves the first part of the theorem.

        Now we prove the second part. Since $T$ is a tree (which is connected), $T + e$ is connected as well. Moreover, $T + e$ contains a unique cycle $C$ from the first part of the theorem. Let $e' \in C$. Then $T + e - e'$ is connected by Lemma 1.9. Then by first part, since $C$ is unique, $T + e - e'$ is acyclic. Thus, $T + e - e'$ is a tree.
    </ProofContent>
</Proof>

## Directed Graphs
<Definition withName={true}>
<DefinitionName>Directed Graph Definitions</DefinitionName>
<DefinitionContent>
    - A **directed graph** (or **digraph**) $D$ is a pair $(N, A)$ where $N$ is a finite set and $A$ is a set of ordered pairs of elements of $N$. The elements of $N$ are called **nodes**, and the elements of $A$ are called **arcs**. An arc $(i,j)$ is also written as $ij$.
    - For an arc $ij$, node $i$ is called the **tail**, and node $j$ is called the **head**.
    - The **out-degree** of a node $v$ is the number of arcs with tail $v$, we write $d(v)$.
    - The **in-degree** of a node $v$ is the number of arcs with head $v$, we write $\bar d(v)$.
    - A **diwalk** $Q$ is a non-empty sequence of arcs $v_1v_2,v_2v_3,\ldots,v_{k-1}v_k$. 

        We can abbreviate this by only writing the nodes: $Q = v_1,v_2,\ldots,v_k$. Note that this implies that $v_iv_{i+1}$ is an arc, and an arc may appear several times in a walk.
    - A **dipath** $P$ is a diwalk such that $v_1,\ldots,v_k$ are distinct nodes.
    - A **dicycle** $C$ is a diwalk such that $k \geq 3$ and $v_1 = v_k$ with $v_1,\ldots,v_{k-1}$ being distinct.
    - An **$st$-diwalk** is a diwalk that starts at $s$ and ends at $t$.
    - An **$st$-dipath** is a dipath that starts at $s$ and ends at $t$, with $s \neq t$.
    - A digraph $D$ that contains no dicycle is **acyclic**.
    - For nodes $s,v$ of digraph $D$, $v$ can be **reached** from $s$ if $D$ has an $sv$-diwalk.
    - $D' = (N', A')$ is called a **subdigraph** of $D = (N, A)$ if $N' \subseteq N$ and $A \subseteq A$.
    - $D' = (N', A')$ is called a **spanning subdigraph** of $D = (N, A)$ if $N' = N$ and $A' \subseteq A$. In other words, $D'$ contains all the nodes of $D$, but only contains a subset of the arcs.
</DefinitionContent>
</Definition>
<Definition>
    <DefinitionName>Digraph Cuts</DefinitionName>
    <DefinitionContent>
        - For $S \subseteq N$, the **cut** with shore $S$ is the set of arcs with **tails in** $S$ and **heads not in** $S$.

            We use the notation 
            $$
            \delta_D(S) = \delta(S) = \{uv \in A: u \in S, v \not \in S\}
            $$
        - For nodes $s, t$ where $s \neq t$ of $D$, an **$st$-cut** of $D$ is a cut $\delta(S)$ where $S \subset N$, with $s \in S$ and $t \not \in S$.
        - Similarly, the cut $\delta(\overline S)$ is the set of arcs with **heads in** $S$ and **tails not in** $S$.
    </DefinitionContent>
</Definition>
<Theorem>
    <TheoremContent>
        Let $D = (N, A)$ be a digraph, and let $s, t$ be distinct nodes of $D$. There exists an $st$-dipath if and only if every $st$-cut is non-empty.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        $(\Rightarrow)$ Let $s = v_1,v_2,\ldots,v_k = t$ be an $st$-dipath. Let $\delta(S)$ be an $st$-cut. Since $v_1 \in S$ and $v_k \not \in S$, there exists a largest index $i$ such that $v_i \in S$ and $i < k$. Then $v_{i + 1} \not \in S$, so $v_i v_{i+1} \in \delta(S)$, so $\delta(S)$ is not empty.

        $(\Leftarrow)$ Assume every $st$-cut is non-empty. We will prove that there exists an $st$-dipath. Let $S$ be the set of all nodes $v$ such that an $sv$-dipath exists. If $t \in S$, then an $st$-dipath exists, and we are done. Otherwise, suppose by contradiction we have $t \not \in S$ (so we assume no $st$-dipath exists) and $\delta(S)$ is an $st$-cut. By assumption, all $st$-cuts are non-empty, so there exists an arc $uv \in \delta(S)$. Since $u \in S$, there exists an $su$-dipath. Then $P + uv$ is an $sv$-dipath, so $v$ is reachable from $s$, and thus $v \in S$. This is a contradiction since $v \not \in S$ by definition of $uv \in \delta(S)$. Therefore, there exists an $st$-dipath.
    </ProofContent>
</Proof>
<Definition>
    <DefinitionName>Underlying Graph</DefinitionName>
    <DefinitionContent>
        - The **underlying graph** of a digraph $D = (N, A)$ is obtained by removing the directions on the arcs in $A$ to obtain edges.
        - A digraph is **connected** if its underlying graph is connected. Therefore, we do not need to care about the directions of the arcs when determining connectivity.
        - A **spanning tree** in a digraph corresponds to a spanning tree in the underlying graph.
        - A **cycle** in a digraph corresponds to a cycle in the underlying graph.
        - Take the cycle in the underlying graph. If we fix a direction, we say that it is an **oriented cycle**. The arcs of the cycles in the digraph that match the oriented cycle are called **forward arcs**, otherwise they are called **backward arcs**.
    </DefinitionContent>
</Definition>
<Definition withName={true}>
<DefinitionName>Node-arc Incidence Matrix</DefinitionName>
<DefinitionContent>
The node-arc incidence matrix of a digraph $D = (N, A)$ is an $|N| \times |A|$ matrix $M$ such that
- its rows are the nodes of $D$
- its columns are the arcs of $D$
- the entry for node $v$ and arc $ij$, $m_{v, ij}$ is given by
    $$
    m_{v, ij} = \begin{cases}
        0 & \text{if $v \neq i$ and $v \neq j$} \\
        1 & \text{if $v = j$} \\
        -1 & \text{if $v = i$}
    \end{cases}
    $$
</DefinitionContent>
</Definition>
Let's illustrate this on an example. Suppose that we have the digraph

![Digraph Example](/images/school/spring-2024/co351/1-4.png)

Then the node-arc incidence matrix $M$ is

| $v \downarrow$ $e \rightarrow$ | 12 | 14 | 24 | 31 | 35 | 43 | 45 | 51 |
|---|---|---|---|---|---|---|---|---|
| 1 | -1 | -1 | 0 | 1 | 0 | 0 | 0 | 1 |
| 2 | 1 | 0 | -1 | 0 | 0 | 0 | 0 | 0 |
| 3 | 0 | 0 | 0 | -1 | 1 | 1 | 0 | 0 |
| 4 | 0 | 1 | 1 | 0 | 0 | -1 | -1 | 0 |
| 5 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | -1 |

Notice that each column has exactly one 1 and one -1, and the rest are 0s. This is because each arc has exactly one tail and one head.

## Transshipment Problem (TP)
In a transshipment problem, we are given a digraph $D = (N, A)$. Each node $v \in N$ has demand $b_v$. The demand can be positive or negative, where positive means that the node demands goods, and negative means that the node supplies goods. Each arc $e \in A$ has arc cost $w_e$.

We need to move all the goods from supply nodes to demand nodes, the solution to this is called a **flow**. Our goal is then to minimize the total cost of the flow.

For example, consider the following digraph on the left. The square boxes next to the nodes are the demands, and the number on the arcs are the cost. A feasible flow is shown on the right. We can see that all the demands are met, and the cost is $5 \cdot 100 + 2 \cdot 80 + 2 \cdot 30 + 3 \cdot 40 = 840$.

![TP Example](/images/school/spring-2024/co351/3-1.png)

### LP Formulation
1. Variables: For each arc $e \in A$, we define a variable $x_e \in \mathbb R$ which represents the flow on arc $e$. Note that all flows $x_e$ are non-negative.
2. Objective function: the cost of transporting $x_e$ on arc $e$ is $w_e x_e$. We want to minimize the total cost, so our objective function is $\min \sum_{e \in A} w_e x_e$, written in vector form, it is $\min w^T x$.
3. Constraints: We can think of a node as having a value, which increases as there is flow going into the node (inflow), and decreases when there is flow going out of the node (outflow). We want this value to be equal to the demand of the node. This gives us the constraint inflow minus outflow equalling the demand. Also, all variables are non-negative, $x_e \geq 0$ for all $e \in A$.

Using the example from above, our full LP is
$$
\begin{align*}
    \min \quad &100 x_{ab} + 30x_{ac} + 50x_{ad} + 80x_{cb} + 40 x_{eb} + 30x_{dc} + 20x_{ce} + 40x_{de} \\
    \text{s.t.}\quad &-x_{ab} - x_{ac} - x_{ad} = -5 \\
    &x_{ab} + x_{cb} + x_{eb} = 7 \\
    &x_{ac} - x_{cb} + x_{dc} - x_{ce} = 0 \\
    &x_{ad} - x_{dc} - x_{de} = -5 \\
    &-x_{eb} + x_{ce} + x_{de} = 3 \\
    &x_e \geq 0 \quad \forall e \in A
\end{align*}
$$
Note that we can use $x \in \mathbb R^A$ to replace $x_e$ for all $e \in A$, and $b \in \mathbb R^N$ for demands, and $w \in \mathbb R^A$ for arc costs. Thus, the objective function can be written as a dot product: $\min w^T x$.

We can use $\delta(v)$ (shorthand for $\delta(\{v\})$) to denote the set of outgoing arcs from node $v$, and $\delta(\overline v)$ (shorthand for $\delta(\overline{\{v\}})$) to denote the set of incoming arcs to node $v$. Moreover, we use the notation $x(S)$ to denote the sum of a vector over a subset. If $x \in \mathbb R^T$ and $S \subseteq T$, then $x(S) = \sum_{i \in S} x_i$. If $x$ is a flow, then the total inflow at $v$ can be written as $x(\delta(\overline v))$, and the total outflow at $v$ can be written as $x(\delta(v))$.

Thus, a general LP for a TP is
$$
\begin{align*}
    \min \quad &w^T x \\
    \text{s.t.}\quad &x(\delta(\overline v)) - x(\delta(v)) = b_v \quad \forall v \in N \\
    &x \geq 0
\end{align*}
$$
Or, we can have a coefficient matrix $M$, where $M$ is the node-arc incidence matrix. Then, the LP can be written as
$$
\begin{align*}
    \min \quad &w^T x \\
    \text{s.t.}\quad &Mx = b \\
    &x \geq 0
\end{align*}
$$

## Dual LP for TP
Recall the dual from [co250](/school/spring-2024/co250-review#finding-the-dual-for-any-lp). Suppose we have the following digraph and its LP:

![Digraph Example](/images/school/spring-2024/co351/4-1.png)
$$
\begin{align*}
    \min \quad &\begin{bmatrix}
        100 & 30 & 50 & 80 & 40 & 30 & 20 & 40
    \end{bmatrix} x \\
    \text{s.t.}\quad \quad &\begin{bmatrix}
        -1 & -1 & -1 & 0 & 0 & 0 & 0 & 0 \\
        1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 \\
        0 & 1 & 0 & -1 & 0 & 1 & -1 & 0 \\
        0 & 0 & 1 & 0 & 0 & -1 & 0 & -1 \\
        0 & 0 & 0 & 0 & 1 & 0 & -1 & 1
    \end{bmatrix} x = \begin{bmatrix}
        -5 \\ 7 \\ 0 \\ -5 \\ 3
    \end{bmatrix} \\
    &x \geq 0
\end{align*}
$$
where the columns of the node-incidence matrix correspond to the arcs in the order $ab, ac, ad, cb, eb, dc, ce, de$, and the rows correspond to the nodes in the order $a, b, c, d, e$. The dual LP is
$$
\begin{align*}
    \max \quad &\begin{bmatrix}
        -5 & 7 & 0 & -5 & 3
    \end{bmatrix}y \\
    \text{s.t.}\quad \quad &\begin{bmatrix}
        -1 & 1 & 0 & 0 & 0 \\
        -1 & 0 & 1 & 0 & 0 \\
        -1 & 0 & 0 & 1 & 0 \\
        0 & 1 & -1 & 0 & 0 \\
        0 & 1 & 0 & 0 & 1 \\
        0 & 0 & 1 & -1 & 0 \\
        0 & 0 & -1 & 0 & -1 \\
        0 & 0 & 0 & -1 & 1
    \end{bmatrix} y \leq \begin{bmatrix}
        100 \\ 30 \\ 50 \\ 80 \\ 40 \\ 30 \\ 20 \\ 40
    \end{bmatrix}
\end{align*}
$$
So in general, for LP
$$
\begin{align*}
    \min \quad &w^T x \\
    \text{s.t.}\quad &x(\delta(\overline v)) - x(\delta(v)) = b_v \quad \forall v \in N \\
    &x \geq 0
\end{align*}
$$
we have the dual LP
$$
\begin{align*}
    \max \quad &b^T y \\
    \text{s.t.}\quad &-y_u + y_v \leq w_{uv} \quad \forall uv \in A
\end{align*}
$$
### Complementary Slackness (CS) Conditions
Recall that the CS conditions are
- $x_i = 0$ or the corresponding dual constraint is tight, and
- $y_j = 0$ or the corresponding primal constraint is tight.

In the context of the TP, since the primal constraints are $x(\delta(\overline v)) - x(\delta(v)) = b_v$ (and thus are already tight), we only have to consider the first condition, i.e. $x_i = 0$ or the corresponding dual constraint is tight. This means that we have the CS conditions

$x_{uv} = 0$ or $-y_u + y_v = w_{uv}$ for all $uv \in A$.

If $-y_u + y_v = w_{uv}$, we call $uv$ a tight arc.

Now, recall that if (P) and (D) is a primal-dual pair, then $x, y$ are optimal solutions to (P) and (D) if and only if
- $x$ is feasible for (P), $y$ is feasible for (D), and 
- $x$ and $y$ satisfy the CS conditions.

So, suppose that we have the same examples as above:

![Digraph Example](/images/school/spring-2024/co351/4-1.png)

Then we have the following digraphs. The left digraph shows a spanning tree (in red) and the corresponding flow (in orange), with the demands shown in the black square boxes. The right digraph shows the same spanning tree, with node potentials shown in the green square boxes. The weights of the arcs are also shown in the right digraph.

We can calculate the node potentials by starting at a node with potential 0, and solving the equation $-y_u + y_v = w_{uv}$ for each arc **in the spanning tree**. In our example, we started with node $a$ and set its potential to 0. Then, we can solve the following series of equations to get the potentials of the other nodes:
$$
\begin{align*}
    -y_a + y_c &= 30 \implies y_c = 30 \\
    -y_c + y_e &= 20 \implies y_e = 50 \\
    -y_d + y_e &= 40 \implies y_d = 10 \\
    -y_e + y_b &= 40 \implies y_b = 90
\end{align*}
$$

![](/images/school/spring-2024/co351/5-1.png)

So, we have that $x$ is feasible, and $x, y$ satisfy the CS conditions. It remains to show that $y$ is feasible. Recall that the dual constraints are $-y_u + y_v \leq w_{uv}$ for all $uv \in A$. We can check that $y$ satisfies these constraints:
$$
\begin{align*}
    -y_a + y_b &= 90 \leq 100 \\
    -y_a + y_c &= 30 \leq 30 \\
    -y_a + y_d &= 10 \leq 50 \\
    -y_c + y_e &= 20 \leq 20 \\
    -y_c + y_b &= 60 \leq 80 \\
    -y_d + y_e &= 40 \leq 40 \\
    -y_e + y_b &= 40 \leq 40 
\end{align*}
$$
Thus, $x, y$ are feasible solutions, and all CS conditions are satisfied, so our flow is optimal.

Now, also recall that by Strong Duality Theorem, if $x, y$ are feasible solutions with same objective values, then they are optimal solutions. We can check that the objective values above are the same.

## Basic Feasible Solutions
Recall that in the Simplex algorithm, we start with a basis. A **basis** consists of a set of linearly independent columns that form a square invertible matrix. Each basis corresponds to a unique **basic solution**. A **basic solution** is a solution where only variables corresponding to the basis can be non-zero, while the rest are zero. What if we apply to the TP?

Suppose we have the following digraph from before:

![Digraph Example](/images/school/spring-2024/co351/4-1.png)

Then the constraints are
$$
\begin{align*}
    \begin{bmatrix}
        -1 & -1 & -1 & 0 & 0 & 0 & 0 & 0 \\
        1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 \\
        0 & 1 & 0 & -1 & 0 & 1 & -1 & 0 \\
        0 & 0 & 1 & 0 & 0 & -1 & 0 & -1 \\
        0 & 0 & 0 & 0 & -1 & 0 & 1 & 1
    \end{bmatrix}x &= \begin{bmatrix}
        -5 \\ 7 \\ 0 \\ -5 \\ 3
    \end{bmatrix}
\end{align*}
$$
To form a basis, we need 5 independent columns. However, this is impossible since the rows are linearly dependent (since adding up all rows gives the zero vector). Thus, the rank is at most 4 and we cannot find 5 independent columns.

However, in Simplex algorithm, we assume that the coefficient matrix has full row rank. If not, we row reduce to get an equivalent system with full row rank, and the size of a basis is equal to the rank of the matrix. In the incidence matrix, since there are $|N|$ rows, and the rows are dependent, the rank of the matrix is at most $|N| - 1$.

Note: Since each column represents an arc, we can ask which arcs to pick so that the corresponding columns form a basis.

### Cycles and the Incidence Matrix
<Proposition>
    <PropositionContent>
        If a set of arcs contains a cycle, then the columns of the incidence matrix corresponding to these arcs are linearly dependent.
    </PropositionContent>
</Proposition>
<Proposition>
    <PropositionContent>
        If a set of arcs does not contain a cycle, then the columns of the incidence matrix corresponding to these arcs are linearly independent.
    </PropositionContent>
</Proposition>
<Proof>
    <ProofContent>
        Suppose that the columns are not independent. Then we have a non-trivial linear combination of the columns that gives the zero vector. For example,
        $$
        2 \begin{bmatrix}
            \vdots \\ \pm 1 \\ \vdots \\ \mp 1 \\ \vdots
        \end{bmatrix} + 0 \begin{bmatrix}
            \vdots \\ \pm 1 \\ \vdots \\ \mp 1 \\ \vdots
        \end{bmatrix} + \ldots + (-1) \begin{bmatrix}
            \vdots \\ \pm 1 \\ \vdots \\ \mp 1 \\ \vdots
        \end{bmatrix} = 0
        $$
        If we look at a row of the equation above (corresponding to a node), then that row must have either 0, or at least 2 non-zero entries. This is because the sum of the entries must be 0. So there cannot be a single non-zero entry in a row. We collect all the non-zero arcs in the linear combination, and the nodes with at least 2 non-zero entries, then we have a digraph where every node is incident with at least 2 arcs. Thus this digraph must have a cycle, contradiction.
    </ProofContent>
</Proof>

Thus, to find independent columns, we find arcs that do not have cycles. To find a basis, we need as many arcs as possible. Thus for connected digraphs, they are spanning trees.

For any connected digraph, a spanning tree must exist. The spanning tree has $|N| - 1$ arcs, corresponding to $|N| - 1$ independent columns. So the rank is at least $|N| - 1$. We also said that the rank is at most $|N| - 1$, so the rank is exactly $|N| - 1$, and we have a basis.

<Theorem>
    <TheoremContent>
        Let $M$ be the incidence matrix of a connected digraph $D = (N,A)$. Then the rank of $M$ is $|N| - 1$. Moreover, a set of $|N| - 1$ columns of $M$ is a basis if and only if the $|N| - 1$ arcs corresponding to these columns is a spanning tree of $D$.
    </TheoremContent>
</Theorem>
Therefore, a basic solution of a TP corresponds to a flow of a spanning tree. In general, to find the basic feasible solution (a flow), we can first find a leaf, then calculate the flow at that leaf. Then, we can remove the leaf and repeat the process until we have a flow for the entire digraph.

In the simplex algorithm, $x$ is always feasible, and the CS conditions are always satisfied. The algorithm then works towards feasibility of $y$. When $y$ becomes feasible, we have optimal solutions.

Notice that in the dual of the TP, we have $-y_u + y_v \leq w_{uv}$ for all $uv \in A$. We can add a slack variable $\bar{w}_{uv}$ to make this an equality constraint:
$$
-y_u + y_v + \bar{w}_{uv} = w_{uv}
$$
Thus, if we calculate the node potentials $y$, we can use it to calculate the reduced cost $\bar{w}_{uv}$. Notice that if $\bar{w}_{uv}$ is negative, then the dual constraint is not satisfied, and thus this is a candidate for the entering arc.
<Definition>
    <DefinitionName>Node Potential and Reduced Cost</DefinitionName>
    <DefinitionContent>
        A vector $y \in \mathbb R^N$ is called a node potential. Given $y$, the reduced cost of arc $uv$ is $\bar{w}_{uv} = w_{uv} + y_u - y_v$. A node potential is **feasible** if $\bar{w}_{uv} \geq 0$ for all $uv \in A$.
    </DefinitionContent>
</Definition>
## Finding a Leaving Arc
<Proposition>
    <PropositionContent>
        Given a digraph $D = (N, A)$ and node demands $b \in \mathbb R^N$, suppose $x \in \mathbb R^A$ satisfies the flow constraints at each node (i.e. $x(\delta(\bar v)) - x(\delta(v)) = b_v$). Let $C$ be a cycle. Suppose we fix a direction of $C$, and let $F, B$ be the set of forward and backward arcs respectively. We define $x' \in \mathbb R^A$ by
        $$
        x'_e = x_e + \begin{cases}
            t & \text{if $e \in F$} \\
            -t & \text{if $e \in B$} \\
            0 & \text{otherwise}
        \end{cases}
        $$
        Then $x'$ also satisfies the flow constraint at each node.
    </PropositionContent>
</Proposition>
Since we need to make sure the flow is non-negative when we subtract $t$ from a flow, for example $x'_e = x_e - t \geq 0$, we have to set $t$ to be the minimum flow $x_e$ such that $e$ is a backward arc. So, $t = \min\{x_e: e \in B\}$.

Then when we update the flow, at least one arc in the cycle has flow 0. We pick one of them as the leaving arc.

## Network Simplex for TP
An assumption is that we have a spanning tree to start with that corresponds to a feasible flow (tree flow). Then the Network Simplex for TP algorithm is as follows:

Given $D = (N, A)$, arc costs $w \in \mathbb R^A$, node demands $b \in \mathbb R^N$, spanning tree $T$ with tree flow $x \in \mathbb R^A$.
1. Calculate node potentials $y$ as follows:
    1. Arbitrarily choose a root node $r$ and set $y_r = 0$ as its node potential.
    2. Solve the other node potentials by $-y_u + y_v = w_{uv}$ for each arc $uv$ in the spanning tree.
2. Calculate reduced costs $\bar{w}_{ij} = w_{ij} + y_i - y_j$ for each arc $ij$ that is not in the spanning tree $T$.
3. If every arc satisfies $\bar{w}_{ij} \geq 0$, then $x$ is optimal and STOP.
4. Otherwise, there exists arc $uv$ such that $\bar{w}_{uv} < 0$. We arbitrarily pick one as the entering arc.
5. $T + uv$ contains a cycle $C$. We fix a direction of $C$ where $uv$ is considered a forward arc in the cycle.
6. Pick $t = \min\{x_e: e \in B\}$, where $B$ is the set of backward arcs in the cycle. Pick the arc that has $t$ flow as the leaving arc.
7. For any forward arcs $e$, update the flow by $x^{\text{new}}_e = x_e + t$, and for any backward arcs $e$, update the flow by $x^{\text{new}}_e = x_e - t$. For all other arcs (that are not in the cycle), the flow remains the same.
8. Replace $T$ with $T + uv - pq$, that is, remove the leaving arc, and add the entering arc to the spanning tree.
9. Go back to step 1.

Here is an example of the Network Simplex for TP algorithm. Suppose we are given a digraph with the following demands and arc costs:

![Digraph Example](/images/school/spring-2024/co351/9-1.png)

Then in the following, each iteration has two digraphs. Both digraph shows the current spanning tree in red. The left digraph shows the flow in orange with node demands in the black square boxes. The right digraph shows the node potentials in the green square boxes, the arc costs in black, and the reduced costs in purple. The purple-boxed reduced cost is the reduced cost of the entering arc, and the corresponding purple arc in the left digraph is the entering arc.

![Iteration 1](/images/school/spring-2024/co351/9-2.png)

![Iteration 2](/images/school/spring-2024/co351/9-3.png)

![Iteration 3](/images/school/spring-2024/co351/9-4.png)

## Economic Interpretation
To gain some intuition on the Network Simplex for TP algorithm, we can think of the following economic interpretation. 

In a TP, we transport goods, and we want to reduce the total shipping cost.

The interpretation of the dual potential is that it is a shadow price. So, the meaning of reduced cost is this:
$$
\bar{w}_{uv} = w_{uv} + y_u - y_v
$$
- $w_{uv}$: cost of transport through $uv$
- $y_u$: cost of buying at node $u$
- $y_v$: money we get for selling at node $v$

So, if $\bar{w}_{uv} = a$, then we lose $a$ dollars by moving through $uv$. That is, if we have positive reduced cost, then that means we are losing money, and if we have negative reduced cost, then we are making money. This is why in Network Simplex, we want to pick an arc that has negative reduced cost as the entering arc.

At the end of network simplex, all arcs with some flow must be in the spanning tree with reduced cost 0, neutral. For arcs not in the tree, they all have non-negative reduced costs, so we will lose money if we have flow through them. Thus, the optimal solution is to have flow only through the arcs in the spanning tree.

## Unbounded TPs
In each iteration of Simplex, we find an entering arc $uv$, and inserting it into $T$ creates a cycle $C$. Suppose that all arcs in the cycle are forward arcs, so we add $t$ to add arcs in $C$. Now, how do we arbitrarily increase flow on $C$ while minimizing total cost?

With non-negative arc costs $w$, this is impossible. However, with negative arc costs, if arcs in $C$ have negative total cost, then we can drive down the total cost arbitrarily by increasing $t$ arbitrarily.

The total cost of arcs in $C$ is $w(C)$. If $w(C) < 0$, we call $C$ a negative dicycle. Let's try to verify the existence of a negative dicycle. Suppose that $\bar{w}_{uv} < 0$, so $uv$ is chosen to be the entering arc. Then suppose we have the following dicycle with all forward arcs.

![Negative Dicycle](/images/school/spring-2024/co351/11-1.png)

We can trace the node potentials around $C$.
$$
\begin{align*}
    \bar{w}_{uv} &= w_{uv} + y_u - y_v \\
    &= w_{uv} + (w_{e_k} + y_{a}) - y_v \\
    &= w_{uv} + (w_{e_k} + w_{e_{k-1}} + y_{b}) - y_v \\
    &= \ldots \\
    &= w_{uv} + w_{e_1} + \cdots + w_{e_k} \\
    &= w(C)
\end{align*}
$$
Thus, $w(C) = \bar{w}_{uv} < 0$, so $C$ is a negative dicycle.

Conversely, if there exists a negative dicycle, does that mean the TP is unbounded? Maybe. Yes, if the TP is feasible.

<Theorem>
    <TheoremContent>
        An instance of a feasible TP is unbounded if and only if there exists a negative directed cycle.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        Look at Martin Pei's Lecture 11 for the proof.
    </ProofContent>
</Proof>

## Finding a Tree Flow
Recall that 