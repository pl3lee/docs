import { Definition, DefinitionName, DefinitionContent, Corollary, CorollaryName, CorollaryContent, Example, ExampleName, ExampleContent, Problem, ProblemName, ProblemContent, Proposition, PropositionName, PropositionContent, Theorem, TheoremName, TheoremContent, Lemma, LemmaName, LemmaContent, Proof, ProofName, ProofContent } from "/components/math";
import { Steps, Callout } from 'nextra/components'

# PMATH 332: Applied Complex Analysis
This is mainly a calculus course, which will extend the concepts of calculus to complex numbers.

## Lecture 1 (May 6, 2024)
### Fundamentals
First consider $\sqrt{-1} \sqrt{-1}$. We can interpret it in 2 ways:
1. $\sqrt{-1} \sqrt{-1} = \sqrt{(-1)(-1)} = \sqrt{1} = 1$
2. $\sqrt{-1} \sqrt{-1} = (\sqrt{-1})^2 = -1$

The problem is the notation. So we need to define complex numbers without using the $\sqrt{\cdot}$ symbol. 
<Definition withName={true} id="defn-imaginary-unit">
    <DefinitionName>Imaginary Unit</DefinitionName>
    <DefinitionContent>
        The imaginary unit $i$ is defined by the property $i^2 = -1$.
    </DefinitionContent>
</Definition>
We can now define a complex number as an ordered pair with a special notation.
<Definition withName={true} id="defn-complex-number">
    <DefinitionName>Complex Number</DefinitionName>
    <DefinitionContent>
        A complex number is an expression 
        $$
        z = a + ib, \quad a, b \in \mathbb{R}
        $$
        where $\def\Re{\operatorname{Re}} a = \Re(z)$ is the real part and $\def\Im{\operatorname{Im}}b = \Im(z)$ is the imaginary part.
    </DefinitionContent>
</Definition>
<Callout type="info" emoji="ℹ️">
  The imaginary part is real.
</Callout>
Now, the set of all complex numbers is $\mathbb C$, and $\mathbb R$ is a subset of $\mathbb C$: $\mathbb R \subset \mathbb C$. The laws of commutativity, associativity, and distributivity hold in $\mathbb C$, and we have the following rules of arithmetic.
<Definition withName={true} id="defn-rules-of-arithmetic">
<DefinitionName>Rules of Arithmetic</DefinitionName>
<DefinitionContent>
Let $z = a + bi$ and $w = c + di$.
1. Then $z = w$ iff $a = c$ and $b = d$.
2. $z + w = (a + c) + (b + d)i$.
3. $z - w = z + (-w) = (a - c) + (b - d)i$.
4. $zw = (a + bi)(c + di) = (ac - bd) + (ad + bc)i$.
5. $\frac{z}{w} = \frac{a + bi}{c + di} = \left( \frac{a + bi}{c + di}\right)\left( \frac{c - di}{c - di}\right) = \frac{(ac + bd) + (bc - ad)i}{c^2 + d^2} = \frac{ac + bd}{c^2 + d^2} + \left( \frac{bc - ad}{c^2 + d^2}\right)i$
</DefinitionContent>
</Definition>
As an example, we have
<Example>
<ExampleContent>
$$
\frac{2 + i}{1 + 2i} = \frac{2 + i}{1 + 2i} \frac{1 - 2i}{1 - 2i} = \frac{4 - 3i}{5}
$$
</ExampleContent>
</Example>
We also have the following useful result.
<Lemma>
<LemmaContent>
We have
$$
\frac{1}{i} = \frac{1}{i} \frac{i}{i} = \frac{i}{i^2} = \frac{i}{-1} = -i
$$
That is,
$$
\frac{1}{i} = -i
$$
</LemmaContent>
</Lemma>
<Callout type="info" emoji="ℹ️">
  Complex numbers cannot be described as positive or negative, and they cannot be ordered ($z < w$ is nonsensical).
</Callout>
<Definition withName={true}>
<DefinitionName>Complex Conjugate</DefinitionName>
<DefinitionContent>
The complex conjugate of $z = a + bi$ is $\overline{z} = a - bi$. An alternative notation is $z^*$.
</DefinitionContent>
</Definition>
The following properties hold for the complex conjugate.
<Lemma withName={true}>
<LemmaName>Properties of Conjugate</LemmaName>
<LemmaContent>
1. $\overline{\overline{z}} = z$.
2. $\overline{z \pm w} = \overline{z} \pm \overline{w}$.
3. $\overline{zw} = \overline{z} \cdot \overline{w}$.
4. $\overline{\left( \frac{z}{w}\right)} = \frac{\overline{z}}{\overline{w}}$.
5. $z + \overline{z} = (a + bi) + (a - bi) = 2a$
6. $z - \overline{z} = (a + bi) - (a - bi) = 2bi$
7. $z\overline{z} = (a + bi)(a - bi) = a^2 + b^2$
</LemmaContent>
</Lemma>
And thus a useful identity is
$$
\begin{align*}
    \mathrm{Re}(z) &= \frac{1}{2} (z + \overline{z}) \\
    \mathrm{Im}(z) &= \frac{1}{2i} (z - \overline{z})
\end{align*}
$$

## Lecture 2 (May 6, 2024)
### Complex Plane
We can associate complex numbers with points in a plane.

![Complex Plane](/images/school/spring-2024/pmath332/2-1.png)

The complex number $z$ can be treated as a vector, and the length of the vector is called the modulus of $z$.
<Definition withName={true} id="defn-modulus">
<DefinitionName>Modulus</DefinitionName>
<DefinitionContent>
The modulus of $z = a + bi$ is $|z| = \sqrt{a^2 + b^2}$. This is the distance of $z$ from the origin. The distance between two numbers $z$ and $w$ is $|z - w|$
</DefinitionContent>
</Definition>
So, even though we cannot write $z_1 < z_2$, we can write $|z_1| < |z_2|$.

We can imagine graphs of $|z|$, $\mathrm{Re}(z)$, and $\mathrm{Im}(z)$ as surfaces above the complex plane. These are functions that have 2 inputs and 1 output. More generally though, our functions will be complex valued (meaning that graphs would require 4 dimensions).

So, the equation $|z - z_0| = r$ represents a circle of radius $r$ centered at $z_0$.

<Example>
<ExampleContent>
Sketch the sets
- $|z| < 3$

This is a circle of radius 3 centered at the origin.

![Circle](/images/school/spring-2024/pmath332/2-2.png)

- $|z| = \mathrm{Im}(z)$

We have $z = x + yi$, so we have the equation
$$
\begin{align*}
    \sqrt{x^2 + y^2} &= y \\
    x^2 + y^2 &= y^2 \\
    x^2 &= 0 \\
    x &= 0 
\end{align*}
$$
with $y$ non-negative. So, we have the positive $y$-axis.

![Positive Y-Axis](/images/school/spring-2024/pmath332/2-3.png)

- $|z - 1| = |z + i|$

We have $z = x + yi$, then 
$$
\begin{align*}
    |z - 1| &= |(x - 1) + yi| = \sqrt{(x - 1)^2 + y^2} \\
    |z + i| &= |x + (y + 1)i| = \sqrt{x^2 + (y + 1)^2}
\end{align*}
$$
So we have the equation
$$
\begin{align*}
    \sqrt{(x - 1)^2 + y^2} &= \sqrt{x^2 + (y + 1)^2} \\
    (x - 1)^2 + y^2 &= x^2 + (y + 1)^2 \\
    x^2 - 2x + 1 + y^2 &= x^2 + y^2 + 2y + 1 \\
    -2x &= 2y \\
    y &= -x
\end{align*}
$$
Alternatively, we can think of this as the set of points $z$, where the distance from $z$ to 1 is equal to the distance from $z$ to $-i$. 

![Line](/images/school/spring-2024/pmath332/2-4.png)
</ExampleContent>
</Example>

### Triangle Inequality
We have
1. $|z_1 + z_2| \leq |z_1| + |z_2|$, and the extended version

    $|z_1 + z_2 + \cdots + z_n| \leq |z_1| + |z_2| + \cdots + |z_n|$
2. $|z_1 + z_2| \geq |z_1| - |z_2|$

### Polar Form
Since $z = x + yi$ can be viewed as a point in a plane, we can describe its location in polar coordinates.

![Polar Coordinates](/images/school/spring-2024/pmath332/2-5.png)

By trigonometry, we have $x = r \cos \theta$ and $y = r \sin \theta$ and thus
$$
\begin{align*}
    z &= x + yi \\
    &= r \cos \theta + r \sin \theta i \\
    &= r(\cos \theta + i \sin \theta) \\
    &= r \mathrm{cis}( \theta)
\end{align*}
$$
Of course, $r = |z| = \sqrt{x^2 + y^2}$ and $\tan \theta = \frac{y}{x}$. We call $\theta$ the argument of $z$ and write $\theta = \arg(z)$.

Note that $\theta = \tan^{-1}\left(\frac{y}{x}\right) \pm 2 \pi k$ for any $k \in \mathbb Z_{\neq 0}$ if $x > 0$. If $x < 0$, then we must add or subtract $\pi$. We illustrate this on an example:

![example](/images/school/spring-2024/pmath332/2-6.png)

We have $\tan^{-1}\left(\frac{1}{1}\right) = \tan^{-1}\left(\frac{-1}{-1}\right)$, so this gives the wrong angle. Thus, we must fix it by adding or subtracting $\pi$ to get the correct $\theta$.
#### Why use polar form?
Watch what happens with multiplication
$$
\begin{align*}
    z_1 z_2 &= r_1(\cos \theta_1 + i \sin\theta_1) r_2(\cos \theta_2 + i \sin\theta_2) \\
    &= r_1r_2 \left[\cos\theta_1 \theta_2 - \sin\theta_1\theta_2 + i(\sin\theta_1 \cos\theta_2 + \cos\theta_1 \sin\theta_2)\right] \\
    &= r_1r_2 \left[\cos(\theta_1 + \theta_2) + i \sin(\theta_1 + \theta_2)\right] \\
    &= r_1r_2 \mathrm{cis}(\theta_1 + \theta_2)
\end{align*}
$$
where we used the trigonometric identities $\cos(a + b) = \cos a \cos b - \sin a \sin b$ and $\sin(a + b) = \sin a \cos b + \cos a \sin b$.

That is, $|z_1 z_2| = |z_1||z_2|$ and $\arg(z_1 z_2) = \arg(z_1) + \arg(z_2)$. So multiplying $z_1$ by $z_2$ magnifies $z_1$ by $|z_2|$ and rotates it by $\arg(z_2)$.

Similarly, 
$$
\frac{z_1}{z_2} = \frac{r_1}{r_2} \mathrm{cis}(\theta_1 - \theta_2)
$$
Euler noticed this behaviour is similar to multiplying exponentials, $(a_1e^{b_1}) (a_2e^{b_2}) = a_1a_2 e^{b_1 + b_2}$, so we define the Euler's formula
<Definition withName={true}>
<DefinitionName>Euler's Formula</DefinitionName>
<DefinitionContent>
$$
e^{i\theta} = \cos \theta + i \sin \theta
$$
</DefinitionContent>
</Definition>
Then we can use properties of $e^x$ instead of trigonometric identities!

## Lecture 3 (May 8, 2024)
### Polar and Exponential Form (Continued)
From last lecture, we wrote $z = x + iy = re^{i\theta}$, where $r = |z|$.
<Callout type="info" emoji="ℹ️">
  $|e^{i\theta}| = 1$ for all $\theta$. This is because
  $$
  |e^{i\theta}| = |\cos \theta + i \sin \theta| = \sqrt{\cos^2 \theta + \sin^2 \theta} = 1
  $$

</Callout>
We extend the definition of $\arg$ and we define $\arg(z)$ to be the **set** of all possible values of $\theta$ which can be used to describe $z$, instead of just a single value $\theta$.

From Lecture 2, we wrote
$$
\arg(z_1z_2) = \arg(z_1) + \arg(z_2)
$$
because $z_1z_2 = r_1r_2 e^{i(\theta_1 + \theta_2)}$. However, this is problematic.

Let's consider $z_1 = z_2 = i$. Then $\arg(z_1z_2) = \arg(-1) = \pi + 2\pi k$. For RHS, we get
$$
\begin{align*}
    \arg(z_1) + \arg(z_2) &= \arg(i) + \arg(i) \\
    &= \left(\frac{\pi}{2} + 2 \pi k_1\right) + \left(\frac{\pi}{2} + 2 \pi k_2\right) \\
    &= \pi + 2\pi(k_1 + k_2)
\end{align*}
$$
That is, we have
$$
\arg(z_1z_2) = \pi + 2\pi(k_1 + k_2)
$$
However, we also have
$$
2 \arg(i) = 2 \left(\frac{\pi}{2} + 2\pi k\right) = \pi + 4 \pi k
$$
Thus we have
$$
\arg(i) + \arg(i) \neq 2 \arg(i)
$$
We wish to identify a specific value of $\arg(z)$, so we have these definition.
<Definition>
<DefinitionName>Principle Value</DefinitionName>
<DefinitionContent>
$\mathrm{Arg}(z)$ is the principle value, by which we mean the one in $(-\pi, \pi)$.
</DefinitionContent>
</Definition>
<Definition>
<DefinitionName>Branch</DefinitionName>
<DefinitionContent>
$\arg_{z_0}(z)$ is a branch of $\arg(z)$, which is the angle in the interval $[z_0, z_0 + 2\pi)$.
</DefinitionContent>
</Definition>
For example, we have $\arg_0(z)$ has range $[0, 2\pi)$.
<Definition>
<DefinitionName>Branch Cut</DefinitionName>
<DefinitionContent>
A branch cut is the angle at the endpoints of the interval.
</DefinitionContent>
</Definition>
<Example>
<ExampleContent>
Consider $\arg_{\pi / 4}(z)$. Then $\theta = \frac{\pi}{4}$ is a branch cut. We also have $\theta = \frac{9\pi}{4}$ as a branch cut, but it is in a different branch.
</ExampleContent>
</Example>

### Converting from Standard Form to Exponential Form
Suppose we have $z = 1 - i$. Then we have the graph

![Graph](/images/school/spring-2024/pmath332/3-1.png)

We can see that $\theta = -\frac{\pi}{4}$, and the modulus is $r = \sqrt{1 + 1} = \sqrt 2$. Thus, we have
$$
z = 1 - i = \sqrt 2 e^{-i\pi/4}
$$
or
$ \sqrt 2 e^{(\frac{\pi}{4} + 2\pi k)i}$ since the angles are equivalent.

Now suppose that we have $z = -1 + \sqrt 3 i$. This is hard to graph, so let's solve this algebraically. We have
$r = |z| = \sqrt{1 + 3} = 2$. And from before,
$$
\tan \theta = \frac{y}{x} = - \sqrt 3
$$
so $\theta = \frac{2\pi}{3} + 2\pi k$. So
$$
z = -1 + \sqrt 3 i = 2 e^{i\frac{2\pi}{3}}
$$

### Converting from Exponential Form to Standard Form
The trick is to think about the unit circle.

Suppose we have $e^{\frac{\pi}{2}i}$. This is a point on the unit circle, with $\theta = \frac{\pi}{2}$. So clearly the point lies on the imaginary axis, and thus $z = i$.

Now suppose that $e^{-\frac{\pi}{2}i}$. This is the same case, but in the opposite direction, so $z = -i$.

Now for $e^{i\pi}$. This is a point on the unit circle, with $\theta = \pi$. So the point lies on the negative real axis, and thus $z = -1$.

Then for $e^{\frac{\pi}{4}i}$, this point lies in the first quadrant, with equal distance from the real and imaginary axes. So we can normalize $1 + i$ to get $z = \frac{1}{\sqrt 2} + \frac{1}{\sqrt 2}i$.

Similarly for $e^{i\frac{3\pi}{4}}$, this point lies in the second quadrant, with equal distance from the real and imaginary axes. So we can normalize $-1 + i$ to get $z = -\frac{1}{\sqrt 2} + \frac{1}{\sqrt 2}i$.

### Advantage of Exponential Form
An advantage of exponential form is that multiplication and division **can** be easier when compared to standard form. However, addition and subtraction are easier in standard form.

An example of division being easier is to consider $z_1 = 1 + i$ and $z_2 = 1 - i$. Then we have
$$
\begin{align*}
    \frac{1 + i}{1 - i} &= \frac{\sqrt 2 e^{\frac{\pi}{4}i}}{\sqrt 2 e^{-\frac{\pi}{4}i}} \\
    &= e^{\frac{\pi}{2}i} = i
\end{align*}
$$
But it does not always become easier. Consider 
$$
\begin{align*}
    \left(\frac{2 + i}{-3 + 2i}\right)(3 - i) &= \frac{\sqrt 5 e^{i \tan^{-1}(\frac{1}{2})}}{\sqrt{13} e^{i(\tan^{-1}(- \frac{2}{3}) + \pi)}} (\sqrt{10} e^{i \tan^{-1}(- \frac{1}{3})}) \\
    &= \frac{\sqrt{50}}{\sqrt{13}} e^{i(\tan^{-1}(\frac{1}{2}) - \tan^{-1}(- \frac{2}{3}) - \pi + \tan^{-1}(- \frac{1}{3}) + \pi)}
\end{align*}
$$
However, the advantage is clearer when we raise to a power.
<Theorem withName={true}>
<TheoremName>Demoivre's Formula</TheoremName>
<TheoremContent>
If $z = re^{i\theta}$, then
$$
z^n = r^n e^{in\theta} = r^n \left[\cos(n\theta) + i \sin(n\theta)\right]
$$
</TheoremContent>
</Theorem>
Here are some examples.
<Example withName={true}>
<ExampleName> Example of using Demoivre's Formula</ExampleName>
<ExampleContent>
We have 3 examples:
$$
\begin{align*}
    (2 + 2i)^3 &= (2 \sqrt 2 e^{\frac{\pi}{4}i})^3 \\
    &= 16 \sqrt 2 e^{\frac{3\pi}{4}i} \\
    &= 16(-1 + i) \\
    (2i)^{-3} &= (2e^{\frac{\pi}{2}i})^{-3} \\
    &= \frac{1}{8} e^{-\frac{3\pi}{2}i} \\
    &= \frac{-i}{8} \\
    (\sqrt 3 + i)^5 &= (2e^{\frac{\pi}{6}i})^5 \\
    &= 32 e^{\frac{5\pi}{6}i} \\
    &= 16(- \sqrt 3 + i)
\end{align*}
$$
</ExampleContent>
</Example>

## Lecture 4 (May 10, 2024)
### Roots
Last time we discussed powers:
$$
z^n = (ie^{i\theta})^n = r^n e^{in\theta}
$$
We can use this rule for powers $\frac{1}{n}$ as well. However, in $\mathbb C$, the notation $z^{\frac{1}{n}}$ is understood to be **multi-valued**. To start, we have to write $z$ as $z = re^{i(\theta + 2\pi k)}$.

Then
$$
z^{\frac{1}{n}} = \left[re^{i\theta + 2\pi k}\right]^{\frac{1}{n}} = r^{\frac{1}{n}} e^{i(\frac{\theta}{n} + \frac{2\pi k}{n})}
$$
This gives $n$ distinct values for $z^{\frac{1}{n}}$, because as $k = n$, the second term in the exponent becomes $+ 2\pi$, which results in the same angle, and thus repeats itself.

#### Examples
<Example>
    <ExampleContent>
        Consider
        $$
        \begin{align*}
            \sqrt{-1} &= (-1)^{\frac{1}{2}} \\
            &= (e^{i(\pi + 2 \pi k)})^{\frac{1}{2}} \\
            &= e^{i(\frac{\pi}{2} + \pi k)}
        \end{align*}
        $$
        Then
        - $k = 0$ gives $\omega_0 = e^{i\pi / 2} = i$
        - $k = 1$ gives $\omega_1 = e^{i(3\pi / 2)} = -i$
        - $k = 2$ gives $\omega_2 = e^{i(5\pi / 2)} = e^{i(\pi / 2)} = i = \omega_0$
        - $k = 3$ gives $\omega_3 = e^{i(7\pi / 2)} = e^{i(3\pi / 2)} = -i = \omega_1$ 
    </ExampleContent>
</Example>
<Example>
    <ExampleContent>
        Find the cube roots of 27. We have
        $$
        \begin{align*}
            (27)^{\frac{1}{3}} &= [27e^{i2\pi k}]^{\frac{1}{3}} \\
            &= \sqrt[3]{27} e^{i\frac{2\pi k}{3}} \\
            &= 3e^{i\frac{2\pi k}{3}}
        \end{align*}
        $$
        Then
        - $k = 0$ gives $\omega_0 = 3$
        - $k = 1$ gives $\omega_1 = 3e^{i\frac{2\pi}{3}} = 3(-\frac{1}{2} + i\frac{\sqrt 3}{2})$
        - $k = 2$ gives $\omega_2 = 3e^{i\frac{4\pi}{3}} = 3(-\frac{1}{2} - i\frac{\sqrt 3}{2})$
    </ExampleContent>
</Example>
<Example>
    <ExampleContent>
        Find the six sixth roots of $-8$. We have
        $$
        \begin{align*}
            (-8)^{\frac{1}{6}} &= [8e^{(\pi + 2\pi k)i}]^{\frac{1}{6}} \\
            &= \sqrt 2 e^{i(\frac{\pi}{6} + \frac{\pi k}{3})} \\
        \end{align*}
        $$
        Then
        - $k = 0$ gives $\omega_0 = \sqrt 2 e^{i\frac{\pi}{6}} = \sqrt 2 \left(\frac{\sqrt 3}{2} + \frac{1}{2}i\right)$
        - $k = 1$ gives $\omega_1 = \sqrt 2 e^{i\frac{3\pi}{6}} = \sqrt 2 i$
        - $k = 2$ gives $\omega_2 = \sqrt 2 e^{i\frac{5\pi}{6}} = \sqrt 2 \left(-\frac{\sqrt 3}{2} + \frac{1}{2}i\right)$
        - $k = 3$ gives $\omega_3 = \sqrt 2 e^{i\frac{7\pi}{6}} = \sqrt 2 \left(-\frac{\sqrt 3}{2} - \frac{1}{2}i\right)$
        - $k = 4$ gives $\omega_4 = \sqrt 2 e^{i\frac{9\pi}{6}} = -\sqrt 2$
        - $k = 5$ gives $\omega_5 = \sqrt 2 e^{i\frac{11\pi}{6}} = \sqrt 2 \left(\frac{\sqrt 3}{2} - \frac{1}{2}i\right)$
        - $k = 6$ gives $\omega_6 = \sqrt 2 e^{i\frac{13\pi}{6}} = \sqrt 2 \left(\frac{\sqrt 3}{2} + \frac{1}{2}i\right)$
    </ExampleContent>
</Example>
<Example>
    <ExampleContent>
        Find the 4th roots of $i$. We have
        $$
        \begin{align*}
            i^{1/4} &= (e^{i(\frac{\pi}{2} + 2\pi k)})^{1/4} \\
            &= e^{i(\frac{\pi}{8} + \frac{\pi k}{2})} \\
            &= e^{\frac{\pi}{8}i},  e^{\frac{5\pi}{8}i}, e^{\frac{9\pi}{8}i}, e^{\frac{13\pi}{8}i}
        \end{align*}
        $$
    </ExampleContent>
</Example>

### Applications to Circuit Analysis Impedance
By engineering convention, we use $j$ instead of $i$ to represent the imaginary unit, and $i$ as the current.

It is known from experience that if a current $i(t)$ passes through a resistor of resistance $R$, the resulting drop in electrical potential energy (voltage, $v(t)$) satisfies the equation
$$
v(t) = Ri(t)
$$
That is, $v = iR$ which is Ohm's Law. We will use an alternating current
$$
i(t) = I \sin(\omega t)
$$
where $I$ is the amplitude of the current and $\omega$ is the frequency. So we can write
$$
v_R(t) = I R \sin(\omega t)
$$
for the voltage across the resistor.

![](/images/school/spring-2024/pmath332/4-1.png)

Now consider a capacitor. A capacitor holds charge with a capacitance $C$. The voltage across the capacitor is related to the current by
$$
v_C(t) = \frac{I}{\omega C} \sin\left(\omega t - \frac{\pi}{2}\right)
$$

![](/images/school/spring-2024/pmath332/4-2.png)

Now consider an inductor. An inductor stores energy in a magnetic field with inductance $L$. The voltage across the inductor is related to the current by
$$
v_L(t) = \omega L I \sin\left(\omega t + \frac{\pi}{2}\right)
$$

![](/images/school/spring-2024/pmath332/4-3.png)

These equations are basically the steady state behavior (think of it as like an equilibrium state) of the circuit.

We will also look at circuits involving combinations of resistors, capacitors, and inductors.

![](/images/school/spring-2024/pmath332/4-4.png)

Normally to get the steady state, we will need to use differential equations, but we can use complex numbers to avoid using differential equations. To do this, we will generalize Ohm's Law.

However, before we start, note the following equations:

1. For resistors in series, we have $R = R_1 + R_2$

![](/images/school/spring-2024/pmath332/4-5.png)

2. For resistors in parallel, we have $\frac{1}{R} = \frac{1}{R_1} + \frac{1}{R_2}$

![](/images/school/spring-2024/pmath332/4-6.png)

Now, as a mathematical trick, we introduce a complex current, $\hat i(t) = Ie^{j \omega t}$. With this, the imaginary part of the current is the actual current:
$$
\begin{align*}
    \mathrm{Im}(\hat i(t)) &= \mathrm{Im}(Ie^{j \omega t}) \\
    &= \mathrm{Im}(I (\cos(\omega t) + j \sin(\omega t))) \\
    &= I \sin(\omega t) \\
    &= i(t)
\end{align*}
$$

## Lecture 5 (May 13, 2024)
### Applications to Circuit Analysis Impedance (Continued)
From last lecture, we are given a current $i(t) = I\sin(\omega t)$, and we had the following laws.
- For a resistor, $v_R(t) = IR\sin(\omega t)$ (Ohm's Law).
- For a capacitor, $v_C(t) = \frac{I}{\omega C}\sin(\omega t - \frac{\pi}{2})$.
- For an inductor, $v_L(t) = \omega L I \sin(\omega t + \frac{\pi}{2})$.

To find the steady state relationship between $i(t)$ and $v(t)$ in a circuit with multiple such components, we introduce a complex current $\hat i(t) = I e^{j\omega t}$, so
$$
i(t) = \mathrm{Im}(\hat i(t))
$$
and a complex voltage $\hat v(t)$.

What $\hat i(t)$ is doing is that imagine we had a circle on the complex plane with radius $I$. As time progresses, the point on the circle moves around the circle at a rate of $\omega$ radians per second. The projection of this point onto the imaginary axis gives us the actual current $i(t)$, this is why we take the imaginary part of $\hat i(t)$. Turns out that if our current is cosine, then we would take the real part of $\hat i(t)$ to be the actual current. We will demonstrate this in an example later.

Considering the three laws, how can we write them in complex form? We can just replace $\sin \theta$ with $e^{j\theta}$, so we have
- For a resistor, $\hat v_R(t) = I R e^{j\omega t}$.
- For a capacitor, $\hat v_C(t) = \frac{I}{j\omega C} e^{j(\omega t - \frac{\pi}{2})} = \frac{I}{j\omega C} e^{j\omega t}e^{-j\frac{\pi}{2}} = -\frac{jI}{\omega C} e^{j\omega t} = \frac{I}{j\omega C} e^{j \omega t}$.
- For an inductor, $\hat v_L(t) = \omega L I e^{j(\omega t + \frac{\pi}{2})} = \omega L I e^{j\omega t} e^{j \frac{\pi}{2}} = j \omega L I e^{j\omega t}$.

So we can write
$$
\hat v = Z i, \quad \text{where } Z = \begin{cases}
    R & \text{for a resistor} \\
    \frac{1}{j\omega C} & \text{for a capacitor} \\
    j\omega L & \text{for an inductor}
\end{cases}
$$
$Z$ is called the **impedance**.
#### Examples
Suppose we are working with a current $i(t) = I \sin t$ (so $\omega = 1$) and it passes through the following circuit:

![](/images/school/spring-2024/pmath332/5-1.png)

We want to find $v(t)$.

We let $\hat i(t) = I e^{jt}$.
- The impedance of the resistor is $Z_R = R = 5$.
- The impedance of the capacitor is $Z_C = \frac{1}{j\omega C} = \frac{1}{0.1j} = \frac{10}{j} = -10j$.

Since they are connected in series, the total impedance is
$$
Z = Z_R + Z_C = 5 - 10j
$$
Therefore
$$
\hat v = Z \hat i = (5 - 10j)Ie^{jt}
$$
Then to get the actual voltage, there are two ways to proceed: using standard form or exponential form.

Using standard form, we have
$$
\begin{align*}
    \hat v &= I(5 - 10j)(\cos t + j \sin t) \\
    &= I[(5 \cos t + 10 \sin t) + j(5 \sin t - 10 \cos t)]
\end{align*}
$$
and the actual voltage is the imaginary part of $\hat v$, which is
$$
v(t) = \mathrm{Im}(\hat v(t)) = I(5 \sin t - 10 \cos t)
$$

If we use exponential form, we have
$$
\begin{align*}
    \hat v &= I \sqrt{125} e^{-j \tan^{-1}(2)} e^{jt} \\
    &= 5 \sqrt 5 I e^{j(t - \tan^{-1}(2))}
\end{align*}
$$
Then $v(t) = 5 \sqrt 5 I \sin(t - \tan^{-1}(2))$.

Now, suppose we are working with the following circuit:

![](/images/school/spring-2024/pmath332/5-2.png)

with current $i(t) = 2 \cos(5t)$. Find $v(t)$.

We let $\hat i(t) = 2 e^{j5t}$. Since we are using cosine, the actual current is the real part $i(t) = \mathrm{Re}(\hat i(t))$.

We have
- $Z_R = 25$
- $Z_L = j \omega L = j5(10) = 50j$
- $Z_C = \frac{1}{j \omega C} = \frac{1}{0.1j} = \frac{10}{j} = -10j$

For the parallel section, we have
$$
\begin{align*}
    \frac{1}{Z_{RL}} &= \frac{1}{Z_R} + \frac{1}{Z_L} \\
    &= \frac{1}{25} + \frac{1}{50j} \\
    &= \frac{2j + 1}{50j}
\end{align*}
$$
So
$$
\begin{align*}
    Z_{RL} &= \frac{50j}{2j + 1} \frac{1 - 2j}{1 - 2j} \\
    &= \frac{100 + 50j}{5} \\
    &= 20 + 10j
\end{align*}
$$
Finally, we have
$$
Z = Z_{RL} + Z_C = (20 + 10j) - 10j = 20
$$
So
$$
\hat v(t) = Z \hat i = 20 \hat i = 40 e^{j5t}
$$
This implies that $v(t) = 40 \cos(5t)$.
### Sets in the Complex Plane
Let $S$ be a set of points in $\mathbb C$. Then
- A **neighborhood** of a point $z_0$ is 
  $$
  N_\epsilon(z_0) = \{z \in \mathbb C : |z - z_0| < \epsilon\}
  $$
  where $\epsilon \in \mathbb R$.
- A **deleted neighborhood** of a point $z_0$ is
  $$
  DN_\epsilon(z_0) = \{z \in \mathbb C : 0 < |z - z_0| < \epsilon\}
  $$
- A point $z_0$ is an **interior point** to $S$ if there exists a neighborhood of $z_0$ with contains only points in $S$.
- A point $z_0$ is an **exterior point** to $S$ if there exists a neighborhood of $z_0$ which contains no points in $S$.
- A point $z_0$ is a **boundary point** of $S$ if every neighborhood of $z_0$ contains some points in $S$ and some points not in $S$.
- The set of all boundary points of $S$ is called the **boundary** of $S$.
- The set $S$ is **open** if it contains none of its boundary points.
- The set $S$ is **closed** if it contains all its boundary points.
  - Note that if $S$ is open, then its complement is closed, and vice versa.
  - The set $S = \mathbb C$ has no boundary points, so it is both open and closed.
- The **closure** of $S$ is the set of $S$ plus its boundary.
- An open set $S$ is **connected** if any two points within it can be connected by a polygonal path lying entirely within $S$.
- An open, connected set $S$ is called a **domain** (not to be confused with the domain of a function).
- A **region** is a domain plus some, none, or all of its boundary points (so every domain can also be called a region).
## Lecture 6 (May 13, 2024)
### Extended Complex Plane ($\mathbb C \cup \{\infty\}$)
We can define a neighborhood of infinity as
$$
N_\epsilon(\infty) = \{z \in \mathbb C : |z| > \frac{1}{\epsilon}\}
$$
for some $\epsilon \in \mathbb R$. The concept of Riemann Sphere can help.

Consider the $x_1x_2$ plane, with a third axis $x_3$, and a unit sphere centered at the origin. If we draw a line from $(0, 0, 1)$ (the north pole) to a point $(x, y, 0)$ on the plane, the line intersects the sphere at two points, one of which is the north pole, and one on the surface of the sphere. Therefore, we get a one-to-one mapping from the plane to the sphere, except for the north pole.

![](/images/school/spring-2024/pmath332/6-1.jpg)

Here are some key realizations:
- The north pole corresponds to $\infty$ (in every direction).
- The south pole corresponds to $z = 0$.
- The equator corresponds to the unit circle $x^2 + y^2 = 1$ ($e^{i\theta} = 1$)
- The domain $|z| > 1$ maps to the northern hemisphere.
- The domain $|z| < 1$ maps to the southern hemisphere.
- Circles and lines in the plane all map to circles on the sphere.

![](/images/school/spring-2024/pmath332/6-2.jpg)
![](/images/school/spring-2024/pmath332/6-3.jpg)

### Functions from $\mathbb C$ to $\mathbb C$
Given a mapping $f: \mathbb C \to \mathbb C$, we will write $w = f(z)$. Since both $z$ and $w$ have real and imaginary parts, we can also write
$$
w = f(x + iy) = u(x, y) + iv(x, y)
$$
#### Examples
Let $f(z) = z^2$. Find the image of
1. the 1st quadrant.

    We know that squaring a number scales the modulus, and doubles the argument. So the image is the 1st and 2nd quadrant. Observe that in the 1st quadrant, $x \geq 0$ and $y \geq 0$. Then, since
    $$
    w = z^2 = (x + iy)^2 = \underbrace{(x^2 - y^2)}_{u(x, y)} + i \underbrace{2xy}_{v(x, y)}
    $$
    We get that $v \geq 0$ (since $x, y \geq 0$), with no restriction on $u$. Thus, the image is the 1st and 2nd quadrant.

    ![](/images/school/spring-2024/pmath332/6-4.png)
2. the strip $1 \leq \mathrm{Re}(z) \leq 2$.

    For a vertical line $x = x_0$, the image is 
    $$
    w = \underbrace{(x_0^2 - y^2)}_{u(x, y)} + i \underbrace{2x_0 y}_{v(x, y)}
    $$
    Rearranging $v = 2x_0 y$, we get $y = \frac{v}{2x_0}$. Substituting this equation into $u = x_0^2 - y^2$, we get
    $$
    u = x_0^2 - \left(\frac{v}{2x_0}\right)^2
    $$
    These are parabolas, so with $x_0 = 1$, we get $u = 1 - \frac{1}{4} v^2$. With $x_0 = 2$, we get $u = 4 - \frac{1}{16} v^2$.

    ![](/images/school/spring-2024/pmath332/6-5.png)

Another example. What does $f(z) = |z|$ do? It maps the whole plane to the positive real axis. That is, it maps domains to intervals on the positive real axis.

Now, what does $f(z) = z - z_0$ do?

This gives 
$$
\begin{align*}
    w &= (x + iy) - (x_0 + iy_0) \\
    &= (x - x_0) + i(y - y_0)
\end{align*}
$$
which is a translation.

How about the mapping $f(z) = iz + i$? The image of the half-space $\mathrm{Re}(z) \geq 1$ under this mapping is 

![](/images/school/spring-2024/pmath332/6-6.png)

How about $f(z) = \bar z$? This is a reflection across the real axis.

The inverse mapping $f(z) = \frac{1}{z}$ is particularly important. Observe that $w = \frac{1}{z} = \frac{1}{re^{i\theta}} = \frac{1}{r} e^{-i\theta}$. That is, if $|z| = r$ and $\text{Arg}(z) = \theta$, then $|w| = \frac{1}{r}$ and $\text{Arg}(w) = -\theta$. 

What is the image of the circle $|z - 1| = 1$ under $f(z) = \frac{1}{z}$?

We can convert to polar form:
$$
\begin{align*}
    |z - 1| &= 1 \\
    (x - 1)^2 + y^2 &= 1 \\
    x^2 + y^2 = 2x \\
    r^2 = 2r \cos \theta \\
    r &= 2 \cos \theta
\end{align*}
$$
Then, under the mapping, we replace $r$ with $\frac{1}{r}$ and $\theta$ with $-\theta$. So we get
$$
\frac{1}{r} = 2 \cos \theta
$$
Rearranging gives
$$
\frac{1}{2} = r \cos \theta
$$
Recall that $x = r \cos \theta$, so we have $x = \frac{1}{2}$, and thus we get the equation of a vertical line.

## Lecture 7 (May 15, 2024)
Here are some more examples.

Find the image of the upper half of the unit circle under the mapping $w = \frac{z}{z + 1}$. A trick to this question is that we can rewrite $w$ as 
$$
w = \frac{z + 1 - 1}{z + 1} = 1 - \frac{1}{z + 1}
$$
Now we can interpret this as a sequence of simpler transformations.
- $z + 1$ shifts the unit circle to the right by 1 unit.
- $\frac{1}{z + 1}$ inverts the circle, which becomes a non-positive vertical line with $x$-intercept at $\frac{1}{2}$.

    ![](/images/school/spring-2024/pmath332/7-1.png)
- $- \frac{1}{z + 1}$ negates both the real and imaginary parts, so the line becomes a non-negative vertical line with $x$-intercept at $-\frac{1}{2}$.
  
    ![](/images/school/spring-2024/pmath332/7-2.png)
- $1 - \frac{1}{z + 1}$ shifts the line to the right by 1 unit, so the image is a non-negative vertical line with $x$-intercept at $\frac{1}{2}$.
    
    ![](/images/school/spring-2024/pmath332/7-3.png)
### Limits and Continuity
We define limits and continuity the same way as in single-variable calculus, except how we treat our new point at infinity, and how absolute values are now replaced with moduli.
#### Definitions
- $\lim_{z \to z_0} f(z) = w_0$ means that for any $\epsilon > 0$, there exists a $\delta > 0$ such that
    $$
    0 < |z - z_0| < \delta \implies |f(z) - w_0| < \epsilon
    $$
- $\lim_{z \to z_0} f(z) = \infty$ means that for any $M > 0$, there exists a $\delta > 0$ such that
    $$
    0 < |z - z_0| < \delta \implies |f(z)| > \frac{1}{\epsilon}
    $$
- $\lim_{z \to \infty}f(z) = w_0$ means that for any $\epsilon > 0$, there exists a $\delta > 0$ such that
    $$
    |z| > \frac{1}{\delta} \implies |f(z) - w_0| < \epsilon
    $$
- $\lim_{z \to \infty} f(z) = \infty$ means that for any $\epsilon > 0$, there exists a $\delta > 0$ such that
    $$
    |z| > \frac{1}{\delta} \implies |f(z)| > \frac{1}{\epsilon}
    $$
- A function $f(z)$ is continuous at $z_0$ if
    $$
    \lim_{z \to z_0} f(z) = f(z_0)
    $$

And based on the definitions above, we have the following theorems.
#### Theorems
- $\lim_{z \to z_0} f(z) = \infty$ if and only if $\lim_{z \to z_0} \frac{1}{f(z)} = 0$.
- $\lim_{z \to \infty} f(z) = w_0$ if and only if $\lim_{z \to 0} f\left(\frac{1}{z}\right) = w_0$.
- $\lim_{z \to \infty} f(z) = \infty$ if and only if $\lim_{z \to 0} \frac{1}{f\left(\frac{1}{z}\right)} = 0$.
- Let $f(z) = u + iv$, and let $z = x_0 + iy_0$ and let $w_0 = u_0 + iv_0$. Then $\lim_{z \to z_0} f(z) = w_0$ if and only if
    $$
    \lim_{(x, y) \to (x_0, y_0)} u(x, y) = u_0
    $$
    and
    $$
    \lim_{(x, y) \to (x_0, y_0)} v(x, y) = v_0
    $$
### Differentiation
We have the formal definition of the derivative as
<Definition>
    <DefinitionName>Derivative</DefinitionName>
    <DefinitionContent>
        Let $f: \mathbb C \to \mathbb C$ and let $z_0 \in \mathbb C$. The derivative of $f$ at $z_0$ is
        $$
        f'(z_0) = \lim_{z \to z_0} \frac{f(z) - f(z_0)}{z - z_0}
        $$
        We can also let $\Delta z = z - z_0$, and write
        $$
        f'(z_0) = \lim_{\Delta z \to 0} \frac{f(z_0 + \Delta z) - f(z_0)}{\Delta z}
        $$
        and hence define the derivative as a function
        $$
        f'(z) = \lim_{\Delta z \to 0} \frac{f(z + \Delta z) - f(z)}{\Delta z}
        $$
    </DefinitionContent>
</Definition>
For functions with analogues in $\mathbb R$, the familiar rules apply (Product, Quotient, Power, Chain Rule).

What about functions without real analogues? For example, is $f(z) = \bar z$ differentiable? Let $z_0$ be arbitrary. Then
$$
\begin{align*}
    f'(z_0) &= \lim_{z \to z_0} \frac{f(z) - f(z_0)}{z - z_0} \\
    &= \lim_{z \to z_0} \frac{\bar z - \bar{z_0}}{z - z_0} \\
    &= \lim_{z \to z_0} \frac{\overline{z - z_0}}{z - z_0}
\end{align*}
$$
then we can write $z - z_0$ as $re^{i\theta}$, where $r = |z - z_0|$ and $\theta = \arg(z - z_0)$, then
$$
\begin{align*}
    f'(z_0) &= \lim_{z \to z_0} \frac{re^{-i\theta}}{re^{i\theta}} \\
    &= \lim_{z \to z_0} e^{-2i\theta}
\end{align*}
$$
Therefore the value of the limit depends on the angle of approach. If we approach along the real axis (i.e. $\theta = 0$ or $\theta = \pi$), then $e^{-2i\theta} = 1$. If we approach along the imaginary axis (i.e. $\theta = \frac{\pi}{2}$ or $\theta = -\frac{\pi}{2}$), then $e^{-2i\theta} = -1$. Since the value $e^{-2i\theta}$ depends on the angle of approach, the limit does not exist, and so $f(z) = \bar z$ is not differentiable.

Why should such a well-behaved function not be differentiable? Consider this. We can view $f(z)$ as a mapping from $(x, y)$ to $(u, v)$ since
$$
f(z) = u(x,y) + iv(x,y) 
$$
This suggests that we have four partial derivatives involved:
- $\frac{\partial u}{\partial x} = u_x$
- $\frac{\partial u}{\partial y} = u_y$
- $\frac{\partial v}{\partial x} = v_x$
- $\frac{\partial v}{\partial y} = v_y$

However, we have defined $f'(z)$ to be a complex number, so it only has **two** components. This means that if $f'(z)$ exists then $u_x,u_y,v_x,v_y$ must be related, and there can only be two independent quantities among them.
### Cauchy-Riemann Equations
<Theorem withName={true}>
    <TheoremName>Cauchy-Riemann Equations</TheoremName>
    <TheoremContent>
        Let $f(z) = u(x,y) + iv(x,y)$ and suppose that $f'(z_0)$ exists. Then at $(x_0,y_0)$ we have $u_x = v_y$ and $v_x = -u_y$.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        We have
        $$
        \begin{align*}
            f(z_0) &= \lim_{\Delta z \to 0} \frac{f(z_0 + \Delta z) - f(z_0)}{\Delta z} \\
            &= \lim_{(\Delta x, \Delta y) \to (0, 0)} \frac{u(x_0 + \Delta x, y_0 + \Delta y) - u(x_0, y_0)}{\Delta x + i\Delta y} \\
            &\quad + i \lim_{(\Delta x, \Delta y) \to (0, 0)} \frac{v(x_0 + \Delta x, y_0 + \Delta y) - v(x_0, y_0)}{\Delta x + i\Delta y}
        \end{align*}
        $$
        Since the derivative exists by assumption, its limit must exist as well, so its value is independent of the path of approach. Approaching along $\Delta y = 0$, we find
        $$
        \begin{align*}
            f'(z_0) &= \lim_{\Delta x \to 0} \frac{u(x_0 + \Delta x, y_0) - u(x_0, y_0)}{\Delta x} \\
            &\quad + i \lim_{\Delta x \to 0} \frac{v(x_0 + \Delta x, y_0) - v(x_0, y_0)}{\Delta x} \\
            &= u_x + iv_x
        \end{align*}
        $$
        If we approach along $\Delta x = 0$ instead, we get
        $$
        \begin{align*}
            f'(z_0) &= \frac{1}{i} (u_y + iv_y) \\
            &= v_y - iu_y
        \end{align*}
        $$
        Now, since $f'(z_0)$ should be the same for both paths, we must have
        $$
        u_x = v_y \quad \text{and} \quad v_x = -u_y
        $$
    </ProofContent>
</Proof>
## Lecture 8 (May 17, 2024)
### Example
Let's give some examples of the Cauchy-Riemann Equations. Is the function $f(z) = |z|^2$ differentiable anywhere?

We have
$$
f(z) = |x + iy|^2 = x^2 + y^2
$$
Thus we have $u(x,y) = x^2 + y^2$ and $v(x,y) = 0$. Hence the partial derivatives are
- $u_x = 2x$
- $u_y = 2y$
- $v_x = 0$
- $v_y = 0$

Then the Cauchy-Riemann Equations require that
- $u_x = v_y$ gives $2x = 0$ which implies $x = 0$
- $v_x = -u_y$ gives $0 = -2y$ which implies $y = 0$

Therefore, $f(z)$ cannot be differentiable unless $x = y = 0$. So we check whether $f'(0)$ exists. We have
$$
\begin{align*}
    f'(0) &= \lim_{\Delta z \to 0} \frac{f(0 + \Delta z) - f(0)}{\Delta z} \\
    &= \lim_{\Delta z \to 0} \frac{|\Delta z|^2}{\Delta z} \\
    &= 0
\end{align*}
$$
why is it 0? We have two ways:
- By Squeeze Theorem, we have $\left| \frac{|\Delta z|^2}{\Delta z} \right| = |\Delta z| \to 0$.
- Recall the equation $|z|^2 = z \bar z$, so we have $\frac{|\Delta z|^2}{\Delta z} = \frac{\Delta z \bar{\Delta z}}{\Delta z} = \bar{\Delta z} \to 0$.

So $f'(0) = 0$.

Let's explain what we did for Squeeze Theorem. Here is the definition of the Squeeze Theorem.
<Theorem withName={true}>
    <TheoremName>Squeeze Theorem</TheoremName>
    <TheoremContent>
        Let $f(z), g(z), h(z)$ be functions such that $f(z) \leq g(z) \leq h(z)$ for all $z$ in some neighborhood of $z_0$, and suppose that
        $$
        \lim_{z \to z_0} f(z) = \lim_{z \to z_0} h(z) = L
        $$
        Then
        $$
        \lim_{z \to z_0} g(z) = L
        $$
    </TheoremContent>
</Theorem>
For our example above, we let $\Delta z = x + iy$, then $|\Delta z| = \sqrt{x^2 + y^2}$, and thus our equation is
$$
\begin{align*}
    \lim_{\Delta z \to 0} \frac{|\Delta z|^2}{\Delta z} &= \lim_{\Delta z \to 0} \frac{x^2 + y^2}{x + iy}
\end{align*}
$$
Then let's find the upper bound and lower bound of the modulus of our expression $\frac{x^2 + y^2}{x + iy}$, so we have 
$$
\begin{align*}
    \left| \frac{x^2 + y^2}{x + iy} \right| &= \frac{|x^2 + y^2|}{|x + iy|} \\
    &= \frac{x^2 + y^2}{\sqrt{x^2 + y^2}} \\
    &= \sqrt{x^2 + y^2} = |\Delta z|
\end{align*}
$$
That is,
$$
\left| \frac{x^2 + y^2}{x + iy} \right| = |\Delta z|
$$
So, we have
$$
- |\Delta z| \leq \frac{x^2 + y^2}{x + iy} \leq |\Delta z|
$$
both bounds approach 0 as $\Delta z \to 0$, so by the Squeeze Theorem, the limit is 0.

### Analytic Functions
Under what condition is $f$ differentiable?
<Theorem>
    <TheoremContent>
        Let $f$ be defined in some neighborhood of $z_0$. If $u_x,u_y, v_x, v_y$ exist in the neighborhood, and satisfies the Cauchy-Riemann Equations at $z_0$, and $u_x,u_y,v_x,v_y$ are continuous at $z_0$, then $f$ is differentiable at $z_0$.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        See textbook page 76-77.
    </ProofContent>
</Proof>
Then, we have the following definition for analytic functions.
<Definition>
    <DefinitionName>Analytic Function</DefinitionName>
    <DefinitionContent>
        A function $f(z)$ is said to be analytic at $z_0$ if $f'(z)$ exists at every point in some neighborhood at $z_0$. If it is analytic everywhere in an open set $S$ then we say it is analytic in $S$.
    </DefinitionContent>
</Definition>
Let's see some examples on determine analyticity. Where is $f(z) = x^2 + iy^2$ analytic? We have
- $u(x,y) = x^2$, so $u_x = 2$ and $u_y = 0$
- $v(x,y) = y^2$, so $v_x = 0$ and $v_y = 2$

Thus we have $u_y = -v_x$ everywhere, and $u_x = v_y$ only if $y = x$. Since the partials are continuous, it is only differentiable at possibly on the line $y = x$. Thus, it is not analytic anywhere (since there is no neighborhood around the line $y = x$ where the function is differentiable).

What about $f(z) = f(x + iy) = (x^3 - 3xy^2) + i(3x^2y - y^3)$ analytic? We have
- $u(x,y) = x^3 - 3xy^2$, so $u_x = 3x^2 - 3y^2$ and $u_y = -6xy$
- $v(x,y) = 3x^2y - y^3$, so $v_x = 6xy$ and $v_y = 3x^2 - 3y^2$

The Cauchy-Riemann Equations are satisfied everywhere, and the partials are continuous everywhere, so it is analytic everywhere.

Notice that
$$
\begin{align*}
    f'(z) &= u_x + iv_x \\
    &=(3x^2 - 3y^2) + i(6xy) \\
    &= 3((x^2 - y^2) + 2xyi) \\
    &= 3z^3
\end{align*}
$$
So in fact, $f(z) = z^3$.

What if $f$ is not given in component form? We know immediately that $f(z) = z^3$ is analytic, because of the following theorem:
<Theorem>
    <TheoremContent>
        Sums, products, quotients, and compositions of analytic functions are analytic, provided that we are not dividing by zero.
    </TheoremContent>
</Theorem>
As an example, $f(z) = \frac{z^3 + 2}{z^2 + 1}$ is analytic everywhere except at $\pm i$.

<Definition>
    <DefinitionName>Singular Point/Singularity</DefinitionName>
    <DefinitionContent>
        If $f$ is not analytic at $z_0$, but is analytic at every point in some **deleted** neighborhood of $z_0$, then $z_0$ is called a singular point, or a singularity, of $f$.
    </DefinitionContent>
</Definition>
<Theorem>
    <TheoremContent>
        Suppose $f$ is analytic in a domain $D$ (an open, connected set). If $f'(z) = 0$ for all $z \in D$, then $f$ is constant in $D$.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        We have 
        $$
        \begin{align*}
            f'(z) &= u_x + iv_x \\
            &= v_y - iu_y
        \end{align*}
        $$
        by the Cauchy-Riemann Equations. So if $f'(z) = 0$, this implies that
        $$
        u_x = v_x = u_y = v_y = 0
        $$
        This implies that $u(x,y) = C_1$ and $v(x,y) = C_2$ for some constants $C_1$ and $C_2$. Thus $f(z) = C_1 + iC_2$.
    </ProofContent>
</Proof>


## Lecture 9 (May 21, 2024)
We start with a theorem that is a direct consequence of the Cauchy-Riemann Equations.
<Theorem withName={true}>
    <TheoremName>Example of Implications of the Cauchy-Riemann Equations</TheoremName>
    <TheoremContent>
        Suppose $f$ is analytic in a domain $D$. If $|f(z) = M$ for a constant $M$ for all $z \in D$, then $f(z)$ is constant in $D$.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        We have $|f(z)| = M$ and we let $f(z) = f(x + iy) = u(x,y) + iv(x,y)$. Then we have $|f(z)|^2 = u^2 + v^2 = M^2$. Differentiating both sides w.r.t. $x$ using Chain rule, we get
        $$
        2u u_x + 2v v_x = 0
        $$
        and similarly differentiating w.r.t. $y$ gives
        $$
        2u u_y + 2v v_y = 0
        $$
        Thus we have the system of equations
        $$
        \begin{align}
            uu_x + vv_x &= 0 \\
            uu_y + vv_y &= 0
        \end{align}
        $$
        If $f$ is analytic, then $v_y = u_x$ and $u_y = -v_x$ by the Cauchy-Riemann Equations. So (2) can be rewritten as
        $$
        \begin{align*}
            -uv_x + vu_x &= 0 \tag{3}
        \end{align*}
        $$
        $v \times (1) - u \times (3)$ gives
        $$
        \begin{align*}
            uvu_x + v^2 u_x + u^2 v_x - uvu_x &= 0 \\
            (u^2 + v^2) v_x &= 0
        \end{align*}
        $$
        So either $u^2 + v^2 = 0$ or $v_x = 0$. If $u^2 + v^2 = 0$, then we have $u = v = 0$, and thus $f = 0$, which is a constant function.

        Otherwise, we have $v_x = 0$ and by the Cauchy-Riemann Equations, we have $u_y = 0$. Similarly, we can show that $u_x = v_y = 0$ by repeating the above procedure, and thus all four partials are zero. Thus $f$ is constant.
    </ProofContent>
</Proof>
### Harmonic Conjugates
An example problem is this. Suppose $u(x, y) = e^{-2x} \cos(2y) + 2y$. Find $v(x,y)$ such that $f(z) = u + iv$ is analytic.

We require that the Cauchy-Riemann Equations are satisfied, so we have
$$
v_y = u_x = -2e^{-2x} \cos(2y)
$$
Therefore we can integrate to find $v$:
$$
\begin{align*}
    v(x, y) &= \int - 2e^{-2x} \cos(2y) \, dy \\
    &= -e^{-2x} \sin(2y) + g(x)
\end{align*}
$$
where $g(x)$ is a constant that depends on $x$. Using the other Cauchy-Riemann Equation, we have
$$
v_x = -u_y = 2e^{-2x} \sin(2y) - 2
$$
Using $v(x,y) = -e^{-2x} \sin(2y) + g(x)$, we can differentiate w.r.t. $x$ to get
$$
v_x = 2e^{-2x} \sin(2y) + g'(x)
$$
So comparing both equations, we get $g'(x) = -2$, and thus $g(x) = -2x + C$. Thus, we have found that
$$
v(x,y) = -e^{-2x} \sin(2y) - 2x + C
$$
So
$$
f(z) = (e^{-2x} \cos(2y) + 2y) + i(-e^{-2x} \sin(2y) - 2x + C)
$$

In particular, we call the functions $v(x,y)$ the **harmonic conjugate** of $u(x,y)$. Note that this is not quite a reciprocal relationship. If $v$ is a harmonic conjugate of $u$, then $-u$ is a harmonic conjugate of $v$. Let's consider an easy example.
<Example>
    <ExampleContent>
        Consider $f_1(z) = z$. It is analytic, and $z = x + iy$. So, the harmonic conjugates of $x$ are $y + C$.

        Meanwhile, $f_2(z) = -iz$, and $-iz = -i(x + iy) = y - ix$. So the harmonic conjugates of $y$ are $-x + C$.
    </ExampleContent>
</Example>
A key result is that not every differentiable function $u(x,y)$ has harmonic conjugates. Consider $u(x,y) = x^3 y$. Setting $v_y = u_x$ raequires $v_y = 3x^2 y$. So $v(x,y) = \frac{3}{2}x^2 y^2 + g(x)$. Then we have $v_x = 3xy^2 + g'(x)$ but $u_y = x^3$. However, $-u_y = -x^3$ cannot equal $v_x = 3xy^2 + g'(x)$.

Then, what kinds of functions will work?

Suppose $f(z)$ is analytic in domain $D$. Let $f(z) = u(x,y) + iv(x,y)$. This means $u_x = v_y$ and $u_y = -v_x$. Differentiating w.r.t. $x$ and $y$ again gives
$$
u_{xx} = v_{yx}
$$
and
$$
u_{yy} = -v_{xy}
$$
Later in the course we may prove that if $f$ is analytic then the 2nd order partial derivatives are all continuous, so $v_{yx} = v_{xy}$. Therefore
$$
u_{xx} + u_{yy} = 0
$$
This is the **Laplace Equation**, often abbreviated as $\nabla^2 u = 0$. This is because
$$
\nabla \cdot \nabla u = \left( \frac{\partial}{\partial x}, \frac{\partial}{\partial y} \right) \cdot \left( \frac{\partial u}{\partial x}, \frac{\partial u}{\partial y} \right) = u_{xx} + u_{yy}
$$
And similarly $v_{xx} + v_{yy} = 0$.

Solutions to Laplace's Equation are called harmonic functions.

### Application to Dirichlet Problem: Preview
<Definition>
    <DefinitionName>Dirichlet Problem</DefinitionName>
    <DefinitionContent>
        Let $D$ be a domain with a piecewise-smooth boundary. A Dirichlet Problem is to find a function which is harmonic in $D$ and takes prescribed values on the boundary of $D$.
    </DefinitionContent>
</Definition>
So, the solutions to the Dirichlet Problem are solutions to Laplace's Equation.
<Example>
    <ExampleContent>
        Solve the Dirichlet Problem $\nabla u^2 = 0$, where $u= 1$ on $y = \frac{1}{x}$ and $u = 4$ on $y = \frac{4}{x}$. Note that $f(z) = z^2$ is analytic, and 
        $$
        \begin{align*}
            z^2 &= (x + iy)^2 \\
            &= (x^2 - y^2) + 2ixy
        \end{align*}
        $$
        so $xy$ is harmonic. Then $u(x,y) = xy$ is the solution (conveniently), since
        $$
        \begin{align*}
            u = xy = 4 &\implies y = \frac{4}{x} \\
            u = xy = 1 &\implies y = \frac{1}{x}
        \end{align*}
        $$
        ![](/images/school/spring-2024/pmath332/9-1.png)
    </ExampleContent>
</Example>
## Lecture 10 (May 22, 2024)
Let's solve another Dirichlet problem. Let $\nabla^2 f = 0$, and $f = 0$ on $xy = 1$, $f = 10$ on $xy = 4$. Observe that $xy$ is harmonic. If $xy$ is harmonic, then so is $Axy + B$. So, we let $f(x,y) = Axy + B$.

Since we have $f = 0$ on $xy = 1$, we have $0 = A + B$. We also have $f = 10$ on $xy = 4$, so $10 = 4A + B$. Solving these equations gives $A = \frac{10}{3}$ and $B = -\frac{10}{3}$. Thus, the function $f(x,y) = \frac{10}{3}(xy - 1)$ is harmonic and satisfies the boundary conditions.

We can think of Dirichlet problems as a way to find the temperature distribution in a region. We can think of $\nabla^2 f$ as the steady state temperature, and the boundary conditions as the temperature at the boundaries. The solution to the Dirichlet problem is the temperature distribution in the region.
<Theorem>
    <TheoremContent>
        Let $f(x,y) = u(x,y) + iv(x,y)$ be analytic in a domain $D$. Then the level curves of $u$ are orthogonal to the level curves of $v$.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        Consider the gradient vectors
        $$
        \begin{align*}
            \nabla u \cdot \nabla v &= (u_x, u_y) \cdot (v_x, v_y) \\
            &= u_xv_x + u_yv_y \\
            &= u_xv_x - v_xu_x \tag*{by C-R Equations} \\
            &= 0
        \end{align*}
        $$
    </ProofContent>
</Proof>
### Elementary Functions
Now, we will generalize familiar functions to $\mathbb C$.
#### Polynomials

An $n$th degree polynomial in $\mathbb C$ has the form
$$
p(z) = a_0 + a_1z + a_2z^2 + \cdots + a_nz^n
$$
where $a_i \in \mathbb C$ and $a_n \neq 0$. Note that polynomials are **entire**, meaning that they are analytic everywhere in $\mathbb C$.

The Fundamental Theorem of Algebra tells us that we can factor any polynomial into linear factors, so we can write
$$
p(z) = a_n(z - z_1)(z - z_2) \cdots (z - z_n)
$$
Note that $z_0$ is a root with multiplicity $k$ if and only if $p(z) = (z-z_0)^k q(z)$ where $q(z_0) \neq 0$.

#### Rational Functions

They are of the form
$$
R(z) = \frac{p(z)}{q(z)}
$$
where all common terms have already been cancelled. The roots (or zeroes) of $p(z)$ are the roots of $R(z)$. The roots of $q(z)$ are called the **poles** (or **singularities**) of $R(z)$. 

Let's look at an example. Let
$$
R(z) = \frac{3i(z - 1)(z - \frac{i}{3})^2(z+i)}{(z-i)^3(z-2-i)}
$$
This has
- simple zeroes at $1$ and $-i$.
- a zero of multiplicity 2 at $\frac{i}{3}$.
- a simple pole at $2 + i$
- a pole of multiplicity 3 at $i$.

Partial fractions have simpler rules when compared to real numbers, but we will get ugly numbers. Also, in $\mathbb R$, we often need all coefficients when performing partial fractions decomposition, but in $\mathbb C$, we may only need one of the coefficients.

For example, consider $R(z) = \frac{1}{(z+4)^2(z^2+1)}$. We know that this can be written as
$$
\begin{align*}
    \frac{1}{(z+4)^2(z^2+1)} &= \frac{1}{(z+4)^2(z+i)(z-i)} \\
    &= \frac{A}{z+4} + \frac{B}{(z+4)^2} + \frac{C}{z+i} + \frac{D}{z-i}
\end{align*}
$$
Normally, we could multiply both sides by the denominator to solve for $A, B, C, D$, but there is a better way. Suppose we want to get $B$. Then we have
$$
\begin{align*}
    \frac{1}{(z+4)^2(z+i)(z-i)} &= \frac{A}{z+4} + \frac{B}{(z+4)^2} + \frac{C}{z+i} + \frac{D}{z-i} \\
    \frac{1}{(z+i)(z-i)} &= A(z+4) + B + \frac{C(z+4)^2}{z+i} + \frac{D(z+4)^2}{z-i}
\end{align*}
$$
Then we can plug in $z = -4$ to cancel everything coefficient except $B$.

So, to get $B$, we can multiply everything by $(z+4)^2$ and then set $z = -4$. That is,
$$
\begin{align*}
    B &= \lim_{z \to -4} (z+4)^2 R(z) \\
    &= \lim_{z \to -4} \frac{1}{z^2 + 1} \\
    &= \frac{1}{17}
\end{align*}
$$
Similarly for $C$, we have
$$
\begin{align*}
    C &= \lim_{z \to -i} (z+i) R(z) \\
    &= \lim_{z \to -i} \frac{1}{(z+4)^2(z-i)} \\
    &= \frac{-8-15i}{578}
\end{align*}
$$
and similarly for $D$ we have
$$
\begin{align*}
    D &= \lim_{z \to i} (z-i) R(z) \\
    &= \lim_{z \to i} \frac{1}{(z+4)^2(z+i)} \\
    &= \frac{-8+15i}{578}
\end{align*}
$$
What about $A$? We can't just plug in $z = -4$ because the denominator is 0 for $B$. Here is a new trick, we can multiply through by $(z+4)^2$, then differentiate, then set $z = -4$. That is,
$$
\begin{align*}
    A &= \lim_{z \to -4} \frac{d}{dz} \left(\frac{1}{z^2 + 1}\right) \\
    &= \lim_{z \to -4} \frac{-2z}{(z^2 + 1)^2} \\
    &= \frac{8}{289}
\end{align*}
$$
## Lecture 11 (May 24, 2024)
### Elementary Functions (Continued)
#### Natural Exponentiation

We have already defined before that
$$
\begin{align*}
    e^z &= e^{x + iy} \\
    &= e^x e^{iy} \\
    &= e^x(\cos y - i\sin y)
\end{align*}
$$
Note that $e^z \neq 0$ for all $z \in \mathbb C$. We have the usual rules
- $e^{z_1}e^{z_2} = e^{z_1 + z_2}$
- $\frac{e^{z_1}}{e^{z_2}} = e^{z_1 - z_2}$
- $\frac{d}{dz} e^z = e^z$

$e^z$ is periodic in $y$.

#### Hyperbolic Functions

Here is a fact. 
<Proposition>
    <PropositionContent>
        Any $f: \mathbb R \to \mathbb R$ can be expressed as the sum of even and odd components:
        $$
        f(x) = \underbrace{\frac{1}{2}[f(x) + f(-x)]}_{\text{even}} + \underbrace{\frac{1}{2} [f(x) - f(-x)]}_{odd}
        $$
    </PropositionContent>
</Proposition>
Applying this to $e^x$, we define
- the hyperbolic cosine of $x$ is $\cosh x = \frac{1}{2}(e^x + e^{-x})$
- the hyperbolic sine of $x$ is $\sinh x = \frac{1}{2}(e^x - e^{-x})$

Note that 
1. $\cosh x + \sinh x = e^x$
2. $\cosh^2 x - \sinh^2 x = \frac{1}{4} (e^{2x} + 2 + e^{-2x}) - \frac{1}{4}(e^{2x} - 2 + e^{-2x})$

This means that we can use the hyperbolic functions to parameterize a unit hyperbola. That is, we can write
$$
\begin{align*}
    x &= \cosh t \\
    y &= \sinh t
\end{align*}
$$
where $t$ is the parameter. This gives $x^2 - y^2 = 1$, which gives a hyperbola.

Here are the graphs of the hyperbolic functions.

![](/images/school/spring-2024/pmath332/11-1.png)

We call them $\sinh, \cosh$ because the hyperbolic functions obey the identities similar to trigonometric identities. The only difference is **Osborne's Rule**, which is that we change the sign of every product of two sines.

For example,
- $\cos(x + y) = \cos x \cos y - \sin x \sin y$
- $\cosh(x + y) = \cosh x \cosh y + \sinh x \sinh y$
- $\cos^2 \theta = \frac{1}{2}(1 + \cos 2\theta)$
- $\cosh^2 x = \frac{1}{2}(1 + \cosh 2x)$ which is the same as above since there are no product of sines.
- $\frac{d}{dx} \sinh x = \frac{d}{dx} \frac{1}{2}(e^x - e^{-x}) = \cosh x$
- $\frac{d}{dx} \cosh x = \frac{d}{dx} \frac{1}{2}(e^x + e^{-x}) = \sinh x$

The hyperbolic functions for complex inputs are defined in the same way as for real inputs.
$$
\begin{align*}
    \cosh z &= \frac{1}{2}(e^z + e^{-z}) \\
    \sinh z &= \frac{1}{2}(e^z - e^{-z})
\end{align*}
$$

#### Trigonometric Functions
    
Consider Euler's formula: $e^{i\theta} = \cos \theta + i \sin \theta$.

Replacing $\theta$ with $-\theta$ gives $e^{-i\theta} = \cos \theta - i \sin \theta$. Adding these two equations gives
$$
\cos \theta = \frac{1}{2}(e^{i\theta} + e^{-i\theta})
$$
and subtracting gives
$$
\sin \theta = \frac{1}{2i}(e^{i\theta} - e^{-i\theta})
$$
So we define
$$
\begin{align*}
    \cos z &= \frac{1}{2}(e^{iz} + e^{-iz}) \\
    \sin z &= \frac{1}{2i}(e^{iz} - e^{-iz})
\end{align*}
$$
We can see that 
$$
\cosh(iz) = \cos z, \quad \sin(iz) = i\sin z
$$
and furthermore,
$$
\cos(iz) = \cosh z, \quad \sin(iz) = i\sinh z
$$
So we have the following
$$
\begin{align*}
    e^z &= e^{x + iy} \\
    &= e^x e^{iy} \\
    &= (\cosh x + \sinh x)(\cos y + i \sin y)
\end{align*}
$$
While $\cos z, \sin z$ are periodic on the real axis, $\cosh z, \sinh z$ are periodic on the imaginary axis. So now we can see why Osborne's rule works.
$$
\begin{align*}
    \cos^2 \theta + \sin^2 \theta &= 1 \\
    \cos^2(ix) + \sin^2(ix) &= 1 \\
    \cosh^2 x + i^2 \sinh^2 x &= 1 \\
    \cosh^2 x - \sinh^2 x &= 1
\end{align*}
$$
And for derivatives, we have
$$
\begin{align*}
    \frac{d}{dz} \sin z &= \frac{d}{dz} \left(\frac{1}{2i}(e^{iz} - e^{-iz})\right) \\
    &= \frac{1}{2i} (ie^{iz} + ie^{-iz}) \\
    &= \cos z
\end{align*}
$$
So, we now have an easy way to evaluate trigonometric functions of complex numbers by using the sum-of-angle identities.
$$
\begin{align*}
    \cos z &= \cos(x + iy) \\
    &= \cos x \cos(iy) - \sin x \sin(iy) \\
    &= \cos x \cosh y - i \sin x \sinh y \\
    \sin z &= \sin x \cosh y + i \cos x \sinh y \\
    \cosh z &= \cosh x \cos y + i \sinh x \sin y \\
    \sinh z &= \sinh x \cos y + i \cosh x \sin y
\end{align*}
$$
which can be calculated easily on a calculator.

For example,
$$
\cos(2 - i) = \cos 2 \cosh 1 + i \sin 2 \sinh 1
$$
and
$$
\begin{align*}
    \sin(\pi + i) &= \sin \pi \cosh 1 + i \cos \pi \sinh 1 \\
    &= -i \sinh 1
\end{align*}
$$
    
## Lecture 12 (May 27, 2024)
### Elementary Functions (Continued)
#### Trigonometric Functions (Continued)
Continuing from the previous section, we start with an example. Find all solutions of the equation $\sin z = 1000$. We have
$$
\begin{align*}
    \sin z &= \sin(x + iy) \\
    &= \sin x \cos(iy) + \cos x \sin(iy) \\
    &= \sin x \cosh y + i \cos \sinh y
\end{align*}
$$
So if $\sin z = 1000$, then matching real and imaginary parts gives us
$$
\begin{align*}
\sin x \cosh y &= 1000 \tag{1} \\
\cos \sinh y &= 0 \tag{2}
\end{align*}
$$
From (2), we get $\cos x = 0$, which implies $x = (2n + 1) \frac{\pi}{2}$ for any integer $n$, or $\sinh y = 0$, which implies $y = 0$.

Looking at (1), 
1. If $y = 0$, then $\cosh y = 1$, and $\sin x = 1000$, which is impossible.
2. If $x = (2n + 1) \frac{\pi}{2}$, then $\sin x = \pm 1$. If $\sin x = -1$, then $\cosh y = -1000$, which is impossible. Therefore $\sin x = 1$. That is,
    $$
    x = (4n + 1) \frac{\pi}{2}
    $$
    which is $\frac{\pi}{2}$ plus a multiple of $2\pi$. With this, $\cosh y = 1000$ and so $y = \pm \cosh^{-1}(1000)$.

So we have 
$$
z = (4n + 1) \frac{\pi}{2} \pm i \cosh^{-1}(1000)
$$
which has the following solutions:

![](/images/school/spring-2024/pmath332/12-1.png)

#### The Natural Logarithm
How should we define this? We let $z = e^w$, and solve for $w$. To do this, we write $w = u + iv$, and write $z = re^{i(\theta + 2\pi k)}$. We can also write
$z = e^w = e^u e^{iv}$. Matching the modulus and argument, we must have $r = e^u$ and $\theta + 2\pi k = v$. Therefore we define
$$
\log z = \ln |z| + i \arg z
$$
<Callout type="info" emoji="ℹ️">
  We use $\ln$ for real inputs, and $\log$ for complex inputs.
</Callout>
Since $e^z$ is periodic, $\log z$ is multivalued. In fact, $e^{\log z} = z$ but $\log e^z = z + 2 \pi k i$.

As an example, we have
$$
\begin{align*}
    \log(1 + i) &= \ln| 1 + i| + i \arg(1 + i) \\
    &= \ln \sqrt 2 + \left(\frac{\pi}{4} + 2 \pi k\right)i
\end{align*}
$$
and
$$
\begin{align*}
    \log(i) &= \left(\frac{\pi}{2} + 2 \pi k\right)i
\end{align*}
$$
If we want a single-valued function, we may pick a branch of $\arg z$.
$$
\mathrm{Log}(z) = \ln|z| + i \mathrm{Arg}(z)
$$
recall that $\mathrm{Arg}(z) \in (-\pi, \pi]$. This is the **principal branch** of $\log z$. Then for other branches, we will write
$$
\mathrm{Log}_t(z) = \ln|z| + i \mathrm{arg}_t(z)
$$
where $\mathrm{arg}_t(z) \in [t, t + 2\pi)$.
<Callout type="info" emoji="ℹ️">
  This is not log base $t$. For logarithms, we only consider base $e$. $t$ is used to describe the branch cut.
</Callout>
For example, we have
$$
\begin{align*}
    \mathrm{Log}(1 + i) &= \frac{1}{2} \ln 2 + \frac{\pi}{4}i \\
    \mathrm{Log}(i) &= \frac{\pi}{2}i
\end{align*}
$$
Notes:
- $\mathrm{Log}(e^z) = z$ iff $\mathrm{Im}(z) \in (-\pi, \pi]$.
- $\mathrm{Log}(z)$ has a discontinuity on the negative real axis.
- $\frac{d}{dz} \mathrm{Log}(z) = \frac{1}{z}$.

We now need to be careful of identities. For example,
$$
\mathrm{Log}(z_1z_2) = \mathrm{Log}(z_1) + \mathrm{Log}(z_2)
$$
is not always true.

<Definition>
    <DefinitionName>Branch, Branch Cut, and Branch Point</DefinitionName>
    <DefinitionContent>
        Let $f$ be a multivalued function. $F(z)$ is said to be a **branch** of $f(z)$ on a domain $D$ if $F(z)$ is continuous on $D$ and for each $z \in D$, $F(z)$ is one and only one value of $f(z)$. Usually, $D$ will abe the place with part of a line removed. This is a **branch cut**. A **branch point** is a point which is common to all possible branch cuts.
    </DefinitionContent>
</Definition>
As an example, find a branch of $f(z) = \log(z + 4)$ which is analytic at $z = -5$, with $F(-5) = 7 \pi i$. We could use $F(z) = \log_{6\pi} (z + 4)$.

## Lecture 13 (May 29, 2024)
### Elementary Functions (Continued)
#### The Natural Logarithm (Continued)
Last time, we had
- $\log z = \ln|z| + i\arg z$
- $\text{Log } z = \ln|z| + i\text{Arg} z$
- $\log_t z = \ln|z| + i \arg_t z$

How does $\text{Log }z$ behave? It is continuous and analytic everywhere except on its branch cut. What happens near the branch cut? Suppose that we have a branch cut along the negative real axis. Suppose that $z_1 = -100 + \epsilon i$ and $z_2 = -100 - \epsilon i$ for a small $\epsilon$ (so $z_1$ and $z_2$ are near the branch cut). Then
$$
\begin{align*}
\text{Log } z_1 &\approx \ln 100 + i\pi \\
\text{Log } z_2 &\approx \ln 100 - i\pi \\
\end{align*}
$$

Let's work on some examples. Where is $\text{Log} (z^2 + 1)$ analytic? It will be analytic as long as $z^2 + 1$ is not on the branch cut of $\text{Log }z$. We must determine where $\text{Re}(z^2 + 1) \leq 0$ and $\text{Im}(z^2 + 1) = 0$ We have
$$
\begin{align*}
  z^2 + 1 &= (x + iy)^2 + 1 \\
  &= (x^2 - y^2 + 1) + i(2xy) 
\end{align*}
$$
So, from the imaginary part, we have to exclude points where $x = 0$ or $y = 0$, and from the real part, $x^2 - y^2 + 1 \leq 0$.

There are no such points with $y = 0$, since if $y = 0$, then $x^2 + 1 \leq 0$ which is impossible. So, we must have $x = 0$. Then $x^2 - y^2 + 1 \leq 0$ means that $y^2 \geq 1$. So, $\text{Log}(z^2 + 1)$ has two branch cuts as shown

![Branch Cuts](/images/school/spring-2024/pmath332/13-1.png)

Now, is $\text{Log}(z^2 + 1)$ equivalent to 
$$
\text{Log}(z^2 + 1) = \text{Log}((z + i)(z - i)) = \text{Log}(z + i) + \text{Log}(z - i)
$$
for all $z \in \mathbb C$? No, because the branch cuts are different. The branch cuts of RHS is as follows

![Branch Cuts](/images/school/spring-2024/pmath332/13-2.png)

However, we can write 
$$
\text{Log}(z^2 + 1) = \log_{t_1}(z + i) + \log_{t_2}(z - i)
$$ 
for some $t_1, t_2$. We must have $t_1 = - \frac{\pi}{2} + 2 \pi m$ and $t_2 = \frac{\pi}{2} + 2 \pi n$ for some $m, n \in \mathbb Z$.

At $z = 0$, we have $\text{Log}(1) = 0$. So we have
$$
\begin{align*}
  0 &= \log_{t_1}(i) + \log_{t_2}(-i) \\
  &= \left(\frac{\pi}{2} + 2 \pi m\right) + \left(\frac{3\pi}{2} + 2\pi n\right) \\
  &= 2 \pi (1 + m + n) \\
  &\implies m + n = -1
\end{align*}
$$
so we may write
$$
\text{Log}(z^2 + 1) = \log_{-\frac{\pi}{2}}(z + i) + \log_{-\frac{3\pi}{2}}(z - i)
$$
or
$$
\text{Log}(z^2 + 1) = \log_{\frac{3\pi}{2}}(z + i) + \log_{-\frac{7\pi}{2}}(z - i)
$$
etc.
#### Roots
Functions such as $f(z) = z^{\frac{1}{2}}$ also require branch cuts. We have the two roots
- $w_1 = |z|^{\frac{1}{2}} e^{i \frac{\theta}{2}}$
- $w_2 = |z|^{\frac{1}{2}} e^{i (\frac{\theta}{2} + \pi)}$

We define $S_1$ to be the branch on which $\theta \in \{\ldots, [-4\pi, -2\pi], [0, 2\pi], [4\pi, 6\pi], \ldots\}$ and $S_2$ to be the branch on which $\theta \in \{\ldots, [-2\pi, 0], [2\pi, 4\pi], [6\pi, 8\pi], \ldots\}$.

#### Complex Powers
<Definition>
  <DefinitionName>Complex Power</DefinitionName>
  <DefinitionContent>
    If $\alpha \in \mathbb C$ and $z \neq 0$, then $z^\alpha$ is defined as
    $$
    z^\alpha = e^{\alpha \log z}
    $$
  </DefinitionContent>
</Definition>
Lets go through some examples.

1.
    $$
    \begin{align*}
        4^{\frac{1}{2}} &= e^{\frac{1}{2} \log 4} \\
        &= e^{\frac{1}{2}(\ln 4 + 2\pi k i)} \\
        &= e^{\ln 2 + \pi k i} \\
        &= 2e^{\pi k i} \\
        &= \pm 2
    \end{align*}
    $$
2.
    $$
    \begin{align*}
        (1 + i)^3 &= \exp[3\log(1 + i)] \\
        &= \exp\left[3(\ln \sqrt{2} + i \frac{\pi}{4} + 2\pi k i)\right] \\
        &= \exp\left[\frac{3}{2} \ln 2 + \left(\frac{3\pi}{4} + 6\pi k\right)i\right] \\
        &= 2^{\frac{3}{2}} e^{\frac{3\pi}{4}i} + e^{6\pi ki} \\
        &= 2^{\frac{3}{2}} \left(-\frac{1}{\sqrt 2} + i \frac{1}{\sqrt 2}\right)(1) \\
        &= -2 + 2i
    \end{align*}
    $$
3.
    $$
    \begin{align*}
        i^i &= e^{i \log i} \\ 
        &= e^{i[(\frac{\pi}{2} + 2\pi k)i]} \\
        &= e^{-\frac{\pi}{2} - 2\pi k}
    \end{align*}
    $$
    So $i^i = \{\ldots, e^{-\frac{5\pi}{2}}, e^{-\frac{\pi}{2}}, e^{\frac{3\pi}{2}}, \ldots\}$.

#### Inverse Trigonometric and Hyperbolic Functions
$y = \sinh^{-1}x$ can be rewritten in terms of logarithms.
$$
\begin{align*}
  y &= \sinh^{-1}x \\
  &= \ln(x + \sqrt{x^2 + 1})
\end{align*}
$$
So we can write
- $\sinh^{-1}z = \log(z + (z^2 + 1)^{\frac{1}{2}})$
- $\cosh^{-1}z = \log(z + (z^2 - 1)^{\frac{1}{2}})$
- $\sin^{-1}z = -i \log(iz + (1 - z^2)^{\frac{1}{2}})$
- $\cos^{-1}z = -i \log(z + (z^2 - 1)^{\frac{1}{2}})$
    
## Lecture 14 (May 31, 2024)
### Integration
Preliminary discussion: If we consider complex-valued functions of real variables, then we just treat $i$ as a constant. That is, if $f(t) = u(t) + iv(t)$, then we have
$$
\int^b_a f(t) dt = \int^b_a u(t) dt + i \int^b_a v(t) dt
$$
For example
$$
\begin{align*}
  \int^1_0 (it^2 + 2)dt &= i\int^1_0 t^2 dt + \int^1_0 2 dt \\
  &= i\left[\frac{t^3}{3}\right]^1_0 + 2[t]^1_0 \\
  &= \frac{i}{3} + 2 \\
  &= 2 + \frac{i}{3}
\end{align*}
$$
Integration involving cosines and sines can be made easier by treating them as components of $e^{i\theta}$.
$$
\begin{align*}
  \int e^{2x} \cos(3x) dx &= \int e^{2x} \text{Re}(e^{i3x}) dx \\
  &= \int \text{Re} (e^{(2 + 3i)x}) dx \\
  &= \text{Re}\left[\int e^{(2 + 3i)x} dx\right] \\
  &= \text{Re}\left[\frac{e^{(2 + 3i)x}}{2 + 3i} + C\right] \\
  &= \text{Re}\left[\left(\frac{2 - 3i}{13}\right)e^{2x}e^{3xi} + C\right] \\
  &= \text{Re}\left[\left(\frac{2 - 3i}{13}\right)e^{2x}(\cos(3x) + i\sin(3x)) + C\right] \\
  &= \frac{e^{2x}}{13}(2\cos 3x + 3\sin 3x) + C_1
\end{align*}
$$
And similarly,
$$
\begin{align*}
  \int e^{2x}(\sin 3x) dx &= \frac{e^{2x}}{13} [2\sin 3x - 3 \cos 3x] + C_2
\end{align*}
$$
To introduce integrals of **complex** variables, we need some definitions.
<Definition>
  <DefinitionName>Curve Definitions</DefinitionName>
  <DefinitionContent>
    - Let $z(t) = x(t) + iy(t)$ be a continuous complex-valued function of a real variable $t$ defined on the interval $[a,b]$. The range of $z(t)$ is called a **smooth curve** if $z'(t) = x'(t) + iy'(t)$ is continuous and non-zero on $[a,b]$.

      Note that we can interpret $z(t)$ as a parameterization of this curve.
    - A curve is called **simple** if $z(t_1) \neq z(t_2)$ whenever $t_1 \neq t_2$ except possibly at the endpoints $t_1 = a$ and $t_2 = b$. In other words, the curve does not cross itself.

    - $z(a)$ and $z(b)$ are called the **initial** and **terminal** points
    - If $z(a) = z(b)$, then $z(t)$ is called a closed curve.
    - A curve composed of finitely many smooth curves joined end-to-end is a **contour**.
    - A simple closed contour is called a **Jordan curve**
    - A Jordan curve is **positively oritned** if the interior is on the left as we follow the curve. In the examples below, all closed curves are positively oriented.

    ![Curves](/images/school/spring-2024/pmath332/14-1.png)
  </DefinitionContent>
</Definition>
<Theorem withName={true}>
  <TheoremName>Jordan Curve Theorem</TheoremName>
  <TheoremContent>
    A Jordan curve separates the plane into two domains, one bounded (the interior) and one unbounded (the exterior).
  </TheoremContent>
</Theorem>
There are 3 basic tools for parameterizing curves.
1. A line segment from $z_0$ to $z_1$ can be parameterized as
    $$
    z = z_0 + (z_1 - z_0) t, \quad t \in [0, 1]
    $$
    For example, if we want to parameterize the following contour
    ![Line Segment](/images/school/spring-2024/pmath332/14-2.png)
    We could write for $C_1$
    $$
    z(t) = (-1 + 3i) - 3ti, \quad t \in [0, 1]
    $$
    For $C_2$,
    $$
    z(t) = -1 + (2 + i)t, \quad t \in [0, 1]
    $$
    To get consecutive values of $t$, we might rewrite $C_2$ as
    $$
    z(t) = -1 + (2 + i)(t - 1), \quad t \in [1, 2]
    $$
2. A circle of radius $r$ centered at $z_0$ can be parameterized as
    $$
    z(t) = z_0 + re^{it}, \quad t \in [0, 2\pi]
    $$
3. To parameterize a curve with equation $y = f(x)$, we simply let 
    $$
    z(t) = t + i f(t)
    $$
    where the first term corresponds to $x = t$, and the second term corresponds to $y = f(t)$.

We can also define the arc length of a contour $C$. If we treat each small segment of the curve as $ds$, then its change in $x$ is $dx$ and change in $y$ is $dy$. The length of $ds$ is
$$
\begin{align*}
  ds &= \sqrt{dx^2 + dy^2} \\
  &\implies \frac{ds}{dt} = \sqrt{\left(\frac{dx}{dt}\right)^2 + \left(\frac{dy}{dt}\right)^2}
\end{align*}
$$
The arc length of the curve is then
$$
\begin{align*}
  \int_C ds &= \int^b_a \frac{ds}{dt} dt \\
  &= \int^b_a \sqrt{\left(\frac{dx}{dt}\right)^2 + \left(\frac{dy}{dt}\right)^2} dt \\
  &= \int^b_a \left|\frac{dz}{dt}\right| dt
\end{align*}
$$

## Lecture 15 (June 3, 2024)
### Integration (Continued)
We first define a path integral in $\mathbb C$. Let $f(z)$ be defined on a set containing a contour $C$. Let $z(t), a \leq t \leq b$ be a parameterization of $C$. We partition $C$ into subcontours by selecting values $t_0,t_1,\ldots,t_n$ such that
$$
a = t_0 < t_1 < \cdots < t_n = b
$$
and such that $\max|\Delta t| \to 0$ as $n \to \infty$.

For each $k =1,2\ldots,n$, we pick $t_k^* \in (t_{k-1},t_k)$, and define
$$
\Delta z_k = z_k - z_{k-1} = z(t_k) - z(t_{k-1})
$$
We can now construct a Riemann sum
$$
\sum^n_{k=1} f(z(t_k^*)) \Delta z_k
$$
(Assuming that the limit exists and is independent of the choice of partition)

- It can be shown that if $f$ is continuous on $C$, then the integral will exist.
- We define the integral of $f$ over a single point to be $0$.
- We will not want to use this definition. Instead, we have a parameterization, so we will use it by defining the integral as
  $$
  \begin{align*}
    \int_C f(z) dz &= \lim_{n \to \infty} \sum^n_{k=1} f(z(t_k^*)) \frac{\Delta z_k}{\Delta t_k} \Delta t_k \\
    &= \int^b_a f(z(t)) \frac{dz}{dt} dt \\
    &= \int^b_a f(z(t)) z'(t) dt
  \end{align*}
  $$
We have the usual properties of integrals:
- $\int_C (f(z) \pm g(z)) dz = \int_C f(z) dz \pm \int_C g(z) dz$
- $\int_C k f(z) dz = k \int_C f(z) dz$
- $\int_{-C} f(z) dz = -\int_C f(z) dz$

But the triangle inequality needs to be modified. Recall that
$$
\left| \int_a^b f(x) dx \right| \leq \int_a^b |f(x)| dx
$$
We cannot just replace $x$ with $z$, since $\int^b_a |f(z)|dz$ is complex, while $\left| \int^b_a f(z) dz \right|$ is real, so the inequality becomes nonsensical. Instead, we have the ML inequality.
<Theorem withName={true}>
  <TheoremName>$ML$ Inequality</TheoremName>
  <TheoremContent>
    If $f(z) = u(x,y) + iv(x,y)$ is continuous on a contour $C$, then $|\int_C f(z) dz | \leq ML$, where $L$ is the length of the curve and $M$ is an upper bound for $|f(z)|$ on $C$. (that is, $|f(z)| \leq M$ on $C$)
  </TheoremContent>
</Theorem>
<Proof>
  <ProofContent>
    Let $z(t), t \in [a, b]$ be a parameterization of $C$. Then
    $$
    \begin{align*}
      \left| \int_C f(z) dz \right| &= \left| \int^b_a f(z(t)) \frac{dz}{dt} dt \right| \\
      &\leq \int^b_a |f(z(t)) z'(t) | dt \\
      &\leq \int^b_a |f(z(t))| |z'(t)| dt \\
      &\leq \int^b_a M \left| \frac{dz}{dt} \right| dt \\
      &= M \int^b_a \left| \frac{dz}{dt} \right| dt \\
      &= ML
    \end{align*}
    $$
  </ProofContent>
</Proof>
Let's work on some examples.

1. Find an upper bound for $\int_C e^{\frac{1}{z}}dz$, where $C$ is the unit circle traversed in the positive direction. Observe that $L = 2\pi$, and we have
    $$
    \begin{align*}
      |e^{\frac{1}{z}}| &= |e^{\frac{1}{x+iy}}| \\
      &= \left| e^{\frac{x}{x^2+y^2}} e^{-i\frac{y}{x^2+y^2}} \right| \\
      &= \left| e^{\frac{x}{x^2 + y^2}} \cdot e^{-i\frac{y}{x^2+y^2}} \right| \\
      &= e^{\frac{x}{x^2 + y^2}} \\
      &= e^x \\
      &\leq e
    \end{align*}
    $$
    since $x \leq 1$. The equality $\left| e^{\frac{x}{x^2 + y^2}} \cdot e^{-i\frac{y}{x^2+y^2}} \right| = e^{\frac{x}{x^2 + y^2}}$ is due to the fact that $|e^{i\theta}| = 1$ for all $\theta$, and the equality $e^{\frac{x}{x^2 + y^2}} = e^x$ is due to the fact that $x^2 + y^2 = 1$ on the unit circle.

    Thus, by the $ML$ inequality, we have
    $$
    \left| \int_C e^{\frac{1}{z}} dz \right| \leq 2\pi e
    $$
2. Evaluate $\int_C \cos z dz$, where $C$ is the line segment from $0$ to $1 + 2i$. We can parameterize $C$:
    $$
    z(t) = (1 + 2i)t, \quad t \in [0,1]
    $$
    so we have $\frac{dz}{dt} = 1 + 2i$, which implies $dz = (1 + 2i)dt$. Thus, we have
    $$
    \begin{align*}
      \int_C \cos z dz &= \int^1_0 \underbrace{\cos((1 + 2i)t)}_{\cos z} \underbrace{(1 + 2i)dt}_{dz} \\
      &= \sin((1 + 2i)t) \Big|_0^1 \\
      &= \sin(1 + 2i)
    \end{align*}
    $$
3. Evaluate $\int_C \cos z dz$, where $C$ is as shown:
    ![Contours](/images/school/spring-2024/pmath332/15-1.png)
    On $C_1$, we can use $z = x, x \in [0, 1]$. Therefore, $dz = dx$.

    On $C_2$, we have $z = 1 + iy, y \in [0, 2]$. Therefore, $dz = idy$. Thus, we have
    $$
    \begin{align*}
      \int_C \cos z dz &= \int_{C_1} \cos z dz + \int_{C_2} \cos z dz \\
      &= \int^1_0 \cos x dx + \int^2_0 \cos(1 + iy) dy \\
      &= \sin x \Big|_0^1 + \sin(1 + iy) \Big|_0^2 \\
      &= \sin 1 + (\sin(1 + 2i) - \sin 1) \\
      &= \sin(1 + 2i)
    \end{align*}
    $$


## Lecture 16 (June 5, 2024)
### Integration (Continued)
Let's continue with more examples.
1. Evaluate $\int_C e^z dz$, where $C$ is the segment of the parabola $y = x^2 + 1$ from $z = i$ to $z = 2 + 5i$.

    Since we have a function $y = x^2 + 1$, we can simply let $t = x$, and we have the parameterization
    $$
    z(t) = t + (t^2 + 1)i, \quad t \in [0, 2]
    $$
    Differentiating both sides and we get
    $$
    dz = (1 + 2ti)dt
    $$
    So, the integral is
    $$
    \begin{align*}
        \int_C e^z dz &= \int^2_0 e^{t + (t^2 + 1)i}(1 + 2ti) dt \\
        &= e^{t + (t^2 + 1)i} \Big|_0^2 \\
        &= e^{2 + 5i} - e^{i}
    \end{align*}
2. Evaluate the integral $\int_C \bar z dz$, where the contour is
    1. $C_a$, the line segment from $0$ to $1 + i$.

        We let $z(t) = (1 + i)t$ with $t \in [0, 1]$. Then $dz = (1 + i)dt$, and
        $$
        \begin{align*}
            \int_{C_a} \bar z dz &= \int^1_0 (1 - i)t (1 + i)dt \\
            &= \int^1_0 2t dt \\
            &= t^2 \Big|_0^1 \\
            &= 1
        \end{align*}
        $$
    2. $C_b$, the arc of the circle $x^2 + (y - 1)^2 = 1$ from $0$ to $1 + i$.
    
            We let $z(t) = e^{it} + i$ with $t \in \left[-\frac{\pi}{2}, 0\right]$, since $e^{it}$ is the parameterization of a circle, and we need to shift it up by 1 unit. Then $dz = ie^{it}dt$, and
            $$
            \begin{align*}
                \int_{C_b} \bar z dz &= \int^0_{-\frac{\pi}{2}} (e^{-it} - i)(ie^{it})dt \\
                &= \int^0_{-\frac{\pi}{2}} (i + e^{it})dt \\
                &= \left[it + \frac{e^{it}}{i}\right]^0_{-\frac{\pi}{2}} \\
                &= \frac{1}{i} - \left(- \frac{\pi}{2} i + \frac{e^{-i \frac{\pi}{2}}}{i}\right) \\
                &= -i + \frac{\pi}{2} i + 1 \\
                &= 1 + \left(\frac{\pi}{2} - 1\right)i
            \end{align*}
            $$

We are now ready for Fundamental Theorem of Calculus.
<Theorem withName={true}>
    <TheoremName>Fundamental Theorem of Calculus - Complex Case</TheoremName>
    <TheoremContent>
        If $f(z)$ is continuous in a domain $D$ and has an antiderivative $F(z)$ throughout $D$, then for any contour $C$ lying in $D$ with initial point $z_1$ and terminal point $z_2$, we have
        $$
        \int_C f(z) dz = F(z_2) - F(z_1)
        $$
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        First suppose $C$ is smooth (so $z'(t)$ exists and is continuous). Let $z(t), t \in [a, b]$ be a parameterization of $C$. Then
        $$
        \int_C f(z) dz = \int^b_a f(z(t)) z'(t) dt
        $$
        If $F'(z) = f(z)$, then this is
        $$
        \begin{align*}
            \int^b_a F'(z(t))z'(t) dt &= \int^b_a \frac{dF}{dt} dt \\
            &= F(z(b)) - F(z(a)) \\
            &= F(z_2) - F(z_1)
        \end{align*}
        $$
        If $C$ is not smooth, then decompose it into smooth subcontours: $C = C_1 + C_2 + \cdots + C_n$. We let $a_0 = z_0,\ldots, a_n = z_n$. Let $a_i$ be the point joining $C_i$ to $C_{i +1}$. Then
        $$
        \begin{align*}
            \int_C f(z) dz &= \int_{C_1} f dz + \int_{C_2} f dz + \cdots + \int_{C_n} fdz \\
            &= [F(a_1) - F(a_0)] + [F(a_2) - F(a_1)] + \cdots + [F(a_n) - F(a_{n - 1})] \\
            &= F(a_n) - F(a_0)
        \end{align*}
        $$
    </ProofContent>
</Proof>
Let's work on some examples to see FTC in action.

1. Evaluate $\int_C (1 + z^2) dz$ where $C$ is as follows:

    ![Contours](/images/school/spring-2024/pmath332/16-1.png)

    We have
    $$
    \begin{align*}
        \int_C (1 + z^2)dz &= \left[z + \frac{z^3}{3}\right]^{4 + 2i}_0 \\
        &= \frac{28}{3} + \frac{94}{3}i
    \end{align*}
    $$
2. Evaluate $\int_C e^z dz$, where $C$ is a simple closed contour. Note that **any** closed contour has integral 0, since the initial and terminal points are the same.

    So, $\int_C e^z dz = 0$.
    
<Theorem>
    <TheoremContent>
        Let $f$ be a continuous function on a domain $D$. Then the following are equivalent:
        1. $f$ has an antiderivative on $D$.
        2. If $C$ is any closed contour in $D$, then $\int_C f(z) dz = 0$.
        3. The contour integrals of $f$ are independent of paths in $C$.
    </TheoremContent>
</Theorem>
<Proof>
    <ProofContent>
        $(1 \to 2)$ A direct consequence of FTC.

        $(2 \to 3)$ Let $C_1$ and $C_2$ be any two contours in $D$ with the same initial and terminal points. Let $C$ be the loop $C_1 + (-C_2)$ ($-C_2$ is $C_2$ but in reverse). Then
        $$
        \begin{align*}
            \int_{C_1} f(z)dz - \int_{C_2} f(z) dz &= \int_{C_1} fdz + \int_{-C_2} fdz \\
            &= \int_C fdz \\
            &= 0
        \end{align*}
        $$
        $(3 \to 1)$ To prove that $f$ has an antiderivative, we will construct it. Pick a point $z_0$ in $D$, and let $C$ be any contour in $D$ with intial point $z_0$ and terminal point $z \in D$. Define $F(z) = \int_C f(w) dw$.

        By assumption, $F(z)$ is single-valued. For any point $z \in D$, pick $\Delta z$ small enough such that the line segment from $z$ to $z + \Delta z$ is in $D$. Let $T$ be this segment and parameterize it as
        $$
        z(t) = z + t \Delta z, \quad t \in [0, 1]
        $$
        Now
        $$
        \begin{align*}
            F(z + \Delta z) - F(z) &= \left[\int_C fdz + \int_D fdz \right] - \int_C fdz \\
            &= \int_T f(z) dz \\
            &= \int^1_0 f(z(t)) z'(t) dt \\
            &= \int^1_0 f(z + t \Delta z) \Delta z dt
        \end{align*}
        $$
        Therefore, if we divide both sides by $\Delta z$, we get
        $$
        \frac{F(z + \Delta z) - F(z)}{\Delta z} = \int^1_0 f(z + t \Delta z) dt
        $$
        Letting $\Delta z \to 0$, we have
        $$
        \begin{align*}
            F'(z) &= \int^1_0 f(z) dt \\
            &= f(z) \int^1_0 dt \\
            &= f(z)
        \end{align*}
        $$
    </ProofContent>
</Proof>